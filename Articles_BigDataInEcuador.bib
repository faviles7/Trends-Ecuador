@article{Buenano-Fernandez2019,
abstract = {The present work proposes the application of machine learning techniques to predict the final grades (FGs) of students based on their historical performance of grades. The proposal was applied to the historical academic information available for students enrolled in the computer engineering degree at an Ecuadorian university. One of the aims of the university's strategic plan is the development of a quality education that is intimately linked with sustainable development goals (SDGs). The application of technology in teaching-learning processes (Technology-enhanced learning) must become a key element to achieve the objective of academic quality and, as a consequence, enhance or benefit the common good. Today, both virtual and face-to-face educational models promote the application of information and communication technologies (ICT) in both teaching-learning processes and academic management processes. This implementation has generated an overload of data that needs to be processed properly in order to transform it into valuable information useful for all those involved in the field of education. Predicting a student's performance from their historical grades is one of the most popular applications of educational data mining and, therefore, it has become a valuable source of information that has been used for different purposes. Nevertheless, several studies related to the prediction of academic grades have been developed exclusively for the benefit of teachers and educational administrators. Little or nothing has been done to show the results of the prediction of the grades to the students. Consequently, there is very little research related to solutions that help students make decisions based on their own historical grades. This paper proposes a methodology in which the process of data collection and pre-processing is initially carried out, and then in a second stage, the grouping of students with similar patterns of academic performance was carried out. In the next phase, based on the identified patterns, the most appropriate supervised learning algorithm was selected, and then the experimental process was carried out. Finally, the results were presented and analyzed. The results showed the effectiveness of machine learning techniques to predict the performance of students.},
address = {Facultad de Ingenier{\'{i}}a y Ciencias Aplicadas, Universidad de Las Am{\'{e}}ricas, Av. de los Granados E12-41 y Colimes, Quito, EC170125, Ecuador},
annote = {Cited By :63

Export Date: 23 March 2023

Correspondence Address: Buena{\~{n}}o-Fern{\'{a}}ndez, D.; Facultad de Ingenier{\'{i}}a y Ciencias Aplicadas, Av. de los Granados E12-41 y Colimes, Ecuador; email: diego.buenano@udla.edu.ec},
author = {Buena{\~{n}}o-Fern{\'{a}}ndez, Diego and Gil, David and Luj{\'{a}}n-Mora, Sergio},
doi = {10.3390/su11102833},
issn = {20711050},
journal = {Sustainability (Switzerland)},
keywords = {Big data,Educational data mining,Learning analytics,Machine learning,Prediction grades},
language = {English},
number = {10},
publisher = {MDPI},
title = {{Application of machine learning in predicting performance for computer engineering students: A case study}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067090157&doi=10.3390%2Fsu11102833&partnerID=40&md5=6e455e0b4797dd61f5d7fbe576810805},
volume = {11},
year = {2019}
}
@article{Rivera2022279,
abstract = {Big data integrates and evaluates large amounts of data collected by a company, which when crossed, allow obtaining indicators that contribute to visualize and improve organizational management in the internal and external environment of a business. The area of communication, marketing and advertising knowledge has been widely benefited by the use and exploitation of data, makes it possible to make intelligent decisions when proposing strategies that are better targeted and adapted to a specific target audience and to objectives specific to the organization, among others, to attract and/or retain consumers or customers; and, evaluate trends and new business opportunities—innovation—to ensure the sustainability of the business. Working under a data mining approach brings additional value and is that the actions implemented can be evaluated in real time or very quickly to improve their effectiveness. The main objective of the study is to demonstrate the criteria according to the experience of those responsible for communication and marketing of companies in Ecuador according to the ranking of the magazine Ekos Business 2019 and the opinion of experts in big data and communication, on the advantages and benefits of big data in the management of the strategic communication of organizations. The results show that, in Ecuador, the use of big data is being adopted for the development of better business and strategic communication strategies.},
annote = {cited By 1},
author = {Rivera, Mario Rom{\'{a}}n and Gonz{\'{a}}lez, Karina Valarezo},
doi = {10.1007/978-981-16-9268-0_23},
issn = {21903026},
journal = {Smart Innovation, Systems and Technologies},
keywords = {Big Data,Business,Communication},
pages = {279--292},
publisher = {Springer Science and Business Media Deutschland GmbH},
title = {{Advantages and Benefits of Big Data in Business Communication}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127689887&doi=10.1007%2F978-981-16-9268-0_23&partnerID=40&md5=269157313f50a3943d6b22343c738f06},
volume = {279},
year = {2022}
}
@article{Villegas-Ch20201,
abstract = {Currently, data are a very valuable resource for organizations. Through analysis, it is possible to profile people or obtain knowledge about an event or environment and make decisions that help improve their quality of life. This concept takes on greater value in the current pandemic, due to coronavirus disease 2019 (COVID-19), that affects society. This emergency has changed the way people live. As a result, the majority of activities are carried out using the internet, virtually or online. Education is not far behind and has seen the web as the most successful option to continue with its activities. The use of any computer application generates a large volume of data that can be analyzed by a big data architecture in order to obtain knowledge from its students and use it to improve educational processes. The big data, when included as a tool for adaptive learning, allow the analysis of a large volume of data to offer an educational model based on personalized education. In this work, the analysis of educational data through a big data architecture is proposed to generate learning based on meeting the needs of students. {\textcopyright} 2020 by the authors. Licensee MDPI, Basel, Switzerland.},
annote = {cited By 9},
author = {Villegas-Ch, William and Roman-Ca{\~{n}}izares, M and Jaramillo-Alc{\'{a}}zar, A and Palacios-Pacheco, X},
doi = {10.3390/app10207016},
file = {:C\:/Users/avile/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Villegas-Ch et al. - 2020 - Data Analysis as a Tool for the Application of Adaptive Learning in a University Environment.pdf:pdf},
issn = {20763417},
journal = {Applied Sciences (Switzerland)},
keywords = {Adaptive learning,Big data,Online education},
number = {20},
pages = {1--19},
publisher = {MDPI AG},
title = {{Data analysis as a tool for the application of adaptive learning in a university environment}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092702917&doi=10.3390%2Fapp10207016&partnerID=40&md5=792f06a310c349cc7166c07eff3754c5},
volume = {10},
year = {2020}
}
@incollection{Ayala-Chauvin2023,
abstract = {Access to basic services, housing, and social security influence people's quality of life. Within the cities, it is common for there to be specific sectors where the presence of those groups that have an abundance of resources predominates. The same occurs with...},
author = {Ayala-Chauvin, Manuel and Maigua, Paola and Medina-Enr{\'{i}}quez, Andrea and Buele, Jorge},
booktitle = {Lecture Notes in Networks and Systems},
doi = {10.1007/978-3-031-25942-5_6},
isbn = {9783031259418},
issn = {23673389},
keywords = {RStudio,Segregation indicators,Social interaction,Spatial segregation},
pages = {64--75},
publisher = {Springer, Cham},
title = {{Socio-spatial Segregation Using Computational Algorithms: Case Study in Ambato, Ecuador}},
url = {https://link.springer.com/chapter/10.1007/978-3-031-25942-5_6 https://link.springer.com/10.1007/978-3-031-25942-5_6},
year = {2023}
}
@inproceedings{Idrovo-Berrezueta2022,
abstract = {Nowadays the WHO (World health Organization) has difficulties improving the access to safe blood. The WHO have published that the problem with blood donations is that of the millions of blood donations that they receive one in four donations made from low-income countries do not test all the donated blood. This is a big problematic because a hospital cannot ensure a patient if the blood, he/she is receiving is safe. As a solution to this problematic, we have proposed the use a method based on CRISP-DM, where as a first procedure we apply a preparation to the data, then we prepared the dataset by cleaning the null variables, transforming the dataset by applying Hot Encoding, analysis the data with PCA (Principal Component Analysis) and using the 85% of variance, and using oversampling for the class that we have chosen. Once the dataset has been preprocessed we proceed to use the techniques of machine learning to help evaluate if a donor's blood is qualified or not for its use. We have applied a variety of machine learning techniques such as: RandomForest, KNN (K-Nearest-Neighbor), SVM (Support Vector Machine), and a neural network ANN (Artificial Neural Network). As a final step, we interpreted the results and got to a conclusion that the classifier that had the highest precision is the Random Forest classifier. For this this research we found a public dataset gathered by the university of Germany. This investigation has the objective to help improve the detection of hepatitis C in low-income countries and hopes to help improve the access to safe blood for patients who need them. In addition, we can apply this data analysis method for future investigations from which we encourage that tests be made with other techniques or models to analyze data.},
author = {Idrovo-Berrezueta, Paul and Dutan-Sanchez, Denys and Hurtado-Ortiz, Remigio and Robles-Bykbaev, Vladimir Espartaco},
booktitle = {2022 IEEE International Autumn Meeting on Power, Electronics and Computing (ROPEC)},
doi = {10.1109/ROPEC55836.2022.10018741},
isbn = {978-1-6654-5892-4},
keywords = {Artificial Neural Network,Blood Donor,Data science,Hepatitis C,K-Nearest-Neighbor,Machine learning,Neural Network,Oversizing,Principal Component Analysis,Random Forest,Support Vector Machine},
month = {nov},
pages = {1--7},
publisher = {IEEE},
title = {{Data Analysis Architecture using Techniques of Machine Learning for the Prediction of the Quality of Blood Fonations against the Hepatitis C Virus}},
url = {https://ieeexplore.ieee.org/document/10018741/},
volume = {6},
year = {2022}
}
@article{Martinez-Mosquera2020,
abstract = {In telecommunications, Performance Management (PM) data are collected from network elements to a centralized system, the Network Management System (NMS), which acts as a business intelligence tool specialized in monitoring and reporting network performance. Performance Management files contain the metrics and named counters used to quantify the performance of the network. Current NMS implementations have limitations in scalability and support for volume, variety, and velocity of the collected PM data, especially for 5G and 6G mobile network technologies. To overcome these limitations, we proposed a Big Data framework based on an analysis of the following components: software architecture, ingestion, data lake, processing, reporting, and deployment. Our work analyzed the PM files&#x2019; format on a real data set from four different vendors and 2G, 3G, 4G, and 5G technologies. Then, we experimentally assessed our proposed framework&#x2019;s feasibility through a case study involving 5G PM files. Test results of the ingestion and reporting components are presented, identifying the hardware and software required to support up to one billion counters per hour. This proposal can help telecommunications operators to have a reference Big Data framework to face the current and future challenges in the NMS, for instance, the support of data analytics in addition to the well-known services.},
author = {Martinez-Mosquera, Diana and Navarrete, Rosa and Luj{\'{a}}n-Mora, Sergio},
doi = {10.1109/ACCESS.2020.3045175},
issn = {21693536},
journal = {IEEE Access},
keywords = {5G mobile communication,6G mobile communication,Big Data,Computer architecture,Lakes,Monitoring,Network Management System,Performance Management,Proposals,framework,mobile networks},
pages = {226380--226396},
title = {{Development and Evaluation of a Big Data Framework for Performance Management in Mobile Networks}},
volume = {8},
year = {2020}
}
@inproceedings{Garcia2018,
abstract = {The adoption of virtualization technologies in the development of software has brought advances in concepts such as flexibility and innovation in the field. The advantages introduced by these emerging solutions are widely known in Cloud Computing and Big Data systems. It should also be noted that these concepts have contributed to spreading such technologies in different contexts. Good examples of this are Cyber-Physical Production Systems (CPPS) and Industrial Internet-of-Things (IIoT) providing the future smart factories with advanced flexibility in production. In this sense, this paper proposes a flexible container architecture for industrial control. More specifically, it is focused on multi-purpose controllers or mobile anthropomorphic robots making use of a container solution. To this end, key technologies as Docker or IEC 61499, are used to address at the same time the deployment of flexible functions and the virtualization of control, with legacy support.},
author = {Garcia, Carlos A. and Garcia, Marcelo V. and Irisarri, Edurne and Perez, Federico and Marcos, Marga and Estevez, Elisabet},
booktitle = {2018 IEEE 23rd International Conference on Emerging Technologies and Factory Automation (ETFA)},
doi = {10.1109/ETFA.2018.8502496},
isbn = {978-1-5386-7108-5},
issn = {19460759},
keywords = {IEC 61499,Industrial Internet-of-Things,Robot Operating System,container virtualization},
month = {sep},
pages = {1056--1059},
publisher = {IEEE},
title = {{Flexible Container Platform Architecture for Industrial Robot Control}},
url = {https://ieeexplore.ieee.org/document/8502496/},
volume = {2018-Septe},
year = {2018}
}
@inproceedings{Piedra2017,
abstract = {During the years 2015 and 2016, one of the natural events which attracted the community's interest was El Ni{\~{n}}o phenomenon, in addition, two health emergencies caused alarm in the population: Zika and Chikungunya. In this paper, authors present the main characterization of the data collected from Twitter during the last manifestation of these events. According to the results obtained, the impact was beyond of the affected areas. Furthermore, the characterization included the temporal distribution, the identification of users and most popular subjects. The authors of this work continue to work on the analysis of data collected in order to find patterns of interaction and user' behavior in relation to health and environmental issues.},
author = {Piedra, N and Chicaiza, J and Torres-Guarnizo, D},
booktitle = {2017 12th Iberian Conference on Information Systems and Technologies (CISTI)},
doi = {10.23919/CISTI.2017.7975939},
isbn = {VO  -},
keywords = {Asia,Big Data,Blogs,Internet,Silicon compounds,Sociology,Twitter,data characterization,epidemics,natural event},
pages = {1--6},
title = {{Characterization of natural events and epidemics from Twitter: El Ni{\~{n}}o, Zika and Chikungunya}},
year = {2017}
}
@article{Castro2019513,
abstract = {OpenStreetMap is perhaps the most successful project from those that produce Volunteered Geographic Information. Its characteristics are the same as the Big Data, which challenges its study. The present paper assesses the horizontal positional accuracy of OSM streets in administrative zones of the Metropolitan District of Quito, with the purpose of understanding what methods allow us to know the quality of these data. Open GIS and statistical programming software were used in combination, and then using the second one as a standalone. Considerations introduced in order to correct two inconveniences of the method are presented. The paper concludes discussing hypotheses regarding positional accuracy and identifying ways to continue the research in this area. {\textcopyright} Springer Nature Switzerland AG 2019.},
annote = {cited By 0; Conference of World Conference on Information Systems and Technologies, WorldCIST 2019 ; Conference Date: 16 April 2019 Through 19 April 2019; Conference Code:224789},
author = {Castro, R and Tierra, A and Luna, M},
doi = {10.1007/978-3-030-16184-2_49},
editor = {{Costanzo S. Reis L.P.}, Adeli H Rocha A},
file = {:C\:/Users/avile/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Castro, Tierra, Luna - 2019 - Assessing the Horizontal Positional Accuracy in OpenStreetMap A Big Data Approach(3).pdf:pdf;:C\:/Users/avile/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Castro, Tierra, Luna - 2019 - Assessing the Horizontal Positional Accuracy in OpenStreetMap A Big Data Approach(4).pdf:pdf},
isbn = {9783030161835},
issn = {21945357},
journal = {Advances in Intelligent Systems and Computing},
keywords = {Big data,Geo-data; Open gis; OpenStreetMap; Positional acc,Information systems; Information use},
pages = {513--523},
publisher = {Springer Verlag},
title = {{Assessing the horizontal positional accuracy in openstreetmap: A big data approach}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065060377&doi=10.1007%2F978-3-030-16184-2_49&partnerID=40&md5=1bc6fb852a1c945ba4d34b35746ce25c},
volume = {931},
year = {2019}
}
@inproceedings{Tejedor2020,
abstract = {The Internet has transformed work dynamics and introduced new tasks, roles and types of content in the journalist's work. These transformations invite us to reflect on the skills and abilities that these communicators must acquire in order to be able to function with solvency in the work scenario. In this sense, communication faculties play a decisive role in achieving this task. Based on this, a comparative study is presented between four universities (Spain: Complutense of Madrid and Aut{\'{o}}noma of Barcelona; and Colombia: Sabana and Rosario, Ecuador: San Francisco University and Eqinoccia University) to find out what presence data journalism has in their respective curricula. In this way, the work analyzes the objectives, the type of subjects, the syllabus and the evaluation system, among other aspects, of the set of subjects of the curricular offer with the objective of identifying which themes and from which approach they work in each center.},
author = {Tejedor, Santiago and Ventin, Augusto and Martinez, F{\'{a}}tima and Tusa, Fernanda},
booktitle = {2020 15th Iberian Conference on Information Systems and Technologies (CISTI)},
doi = {10.23919/CISTI49556.2020.9141013},
file = {:C\:/Users/avile/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Tejedor et al. - 2020 - Emerging lines in the teaching of university communication the inclusion of data journalism in universities in S.pdf:pdf},
isbn = {978-989-54659-0-3},
keywords = {Higher Education,cyber journalism,data journalism,journalists,training,university education},
mendeley-tags = {Higher Education,cyber journalism,data journalism,journalists,training,university education},
month = {jun},
pages = {1--9},
publisher = {IEEE},
title = {{Emerging lines in the teaching of university communication the inclusion of data journalism in universities in Spain, Colombia and Ecuador}},
url = {https://ieeexplore.ieee.org/document/9141013/},
volume = {2020-June},
year = {2020}
}
@inproceedings{Andrade2018,
abstract = {The present work focuses on analyzing the opportunities that emerging Big data technologies offer to enhance the cognitive processes that security analysts must execute day after day. Human capacities can be affected by external factors such as high stress, insufficient knowledge, uncertain information sources. These factors might generate a high number of false alerts that can impact the cybersecurity of the organization. Big data technologies can be exploited to overcome the issues mentioned above and gain insights that lead to better decisions, and strategic organization actions. This will allow obtaining the full value from the massive amounts of information the organization already has.},
author = {Andrade, Roberto and Torres, Jenny and Tello-Oquendo, Luis},
booktitle = {2018 International Conference on Computational Science and Computational Intelligence (CSCI)},
doi = {10.1109/CSCI46756.2018.00026},
isbn = {978-1-7281-1360-9},
keywords = {Big-data,Cognitive security,Incident reponse,Security operations,Situation awareness},
month = {dec},
pages = {100--105},
publisher = {IEEE},
title = {{Cognitive Security Tasks Using Big Data Tools}},
url = {https://ieeexplore.ieee.org/document/8947693/},
year = {2018}
}
@inproceedings{Abad2012,
abstract = {Efficient namespace metadata management is increasingly important as next-generation file systems are designed for peta and exascales. New schemes have been proposed; however, their evaluation has been insufficient due to a lack of appropriate namespace metadata traces. Specifically, no Big Data storage system metadata trace is publicly available and existing ones are a poor replacement. We studied publicly available traces and one Big Data trace from Yahoo! and note some of the differences and their implications to metadata management studies. We discuss the insufficiency of existing evaluation approaches and present a first step towards a statistical metadata workload model that can capture the relevant characteristics of a workload and is suitable for synthetic workload generation. We describe Mimesis, a synthetic workload generator, and evaluate its usefulness through a case study in a least recently used metadata cache for the Hadoop Distributed File System. Simulation results show that the traces generated by Mimesis mimic the original workload and can be used in place of the real trace providing accurate results. {\textcopyright} 2012 IEEE.},
author = {Abad, Cristina L. and Luu, Huong and Roberts, Nathan and Lee, Kihwal and Lu, Yi and Campbell, Roy H.},
booktitle = {Proceedings - 2012 IEEE/ACM 5th International Conference on Utility and Cloud Computing, UCC 2012},
doi = {10.1109/UCC.2012.27},
isbn = {9780769548623},
keywords = {Big data,HDFS,MDS,Metadata,Storage},
pages = {125--132},
title = {{Metadata traces and workload models for evaluating big storage systems}},
year = {2012}
}
@conference{Cruz20194055,
abstract = {Quantifying income inequalities in developing countries faces challenges regarding data publicly available. Census data, collected every five or ten years, is the only source for socioeconomic indicators. Thus, local authorities need ways of producing more frequently updated indicators. Studies conducted for developed countries (Europe and USA) use Call Detail Records (CDRs) for such a purpose. In our study we propose to exploit patterns observed in developing countries, specifically in Latin America, where mobile phone usage is pervasive even among the poorest and the dominant modality for purchasing mobile airtime is the prepaid scheme (top-ups). We analyze more than 1M top-up transactions together with more than 5K online classified ads for housing sales to predict the socioeconomic status measured at an intra-urban level for 89 neighborhoods. Using a Linear Regression with Regularization L1 (Lasso), we can explain the economic status with a prediction rate up to 71% for urban neighborhoods in Guayaquil, Ecuador. Consequently, we show evidence that top-up transactions provide effective signals to characterize urban neighborhoods socioeconomic status.},
annote = {cited By 3; Conference of 2019 IEEE International Conference on Big Data, Big Data 2019 ; Conference Date: 9 December 2019 Through 12 December 2019; Conference Code:157991},
author = {Cruz, Eduardo and Vaca, Carmen and Avendano, Allan},
booktitle = {Proceedings - 2019 IEEE International Conference on Big Data, Big Data 2019},
doi = {10.1109/BigData47090.2019.9005654},
editor = {{Baru C. Huan J.}, Khan L Hu X T Ak R Tian Y Barga R Zaniolo C Lee K Ye Y F},
file = {:C\:/Users/avile/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Cruz, Vaca, Avendano - 2019 - Mining top-up transactions and online classified ads to predict urban neighborhoods socioeconomic status.pdf:pdf;:C\:/Users/avile/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Cruz, Vaca, Avendano - 2019 - Mining top-up transactions and online classified ads to predict urban neighborhoods socioeconomic statu(2).pdf:pdf},
isbn = {9781728108582},
keywords = {classified ads,data science,socioeconomic status,top-up transactions,urban computing},
pages = {4055--4062},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Mining top-up transactions and online classified ads to predict urban neighborhoods socioeconomic status}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081370144&doi=10.1109%2FBigData47090.2019.9005654&partnerID=40&md5=c21250285b43984e83d5b59a9102c2a0},
year = {2019}
}
@inproceedings{Martinez-Mosquera2022,
abstract = {This article presents an approach to managing an educational analytical system in a data lake. This solution covers higher education institutions' requirements for managing large volumes generated by their students and teachers. This work deals with the problem of the lack of organization when implementing a data lake due to the fact that there are no well-known or standardized methods for its administration. Our methodology proposes dividing the data lake into three zones: (1) landing tier, (2) staging tier, and (3) consumption tier, and transforming the data for each zone under the guidance of the Common Data Model and One Data Model. The main goal is to avoid the educational data lake from converting into a data swamp. This methodology was implemented at University as a case study over an open-source data lake environment. The results obtained figures that historical data analysis barriers are overcome thanks to the high capabilities of the data lake. In addition, this approach can be applied to other institutions with great flexibility, with commodity solutions, and regardless of the source data format.},
address = {Escuela Polit{\'{e}}cnica Nacional, Digital School, Universidad Internacional SEK, Department of Informatics and Computer Science, Quito, Ecuador},
annote = {Export Date: 23 March 2023},
author = {Martinez-Mosquera, Diana and Beltr{\'{a}}n, Ver{\'{o}}nica and Riofr{\'{i}}o-Luzcando, Diego and Carri{\'{o}}n-Jumbo, Joe},
booktitle = {6th IEEE Ecuador Technical Chapters Meeting, ETCM 2022},
doi = {10.1109/ETCM56276.2022.9935751},
editor = {D.R., Lalaleo and M.K., Huerta},
isbn = {9781665487443},
keywords = {HDFS,big data,common data model,data lake,education,one data model},
language = {English},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Data Lake Management for Educational Analysis}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142432062&doi=10.1109%2FETCM56276.2022.9935751&partnerID=40&md5=496abc6f1927b961b9103f899cb16728},
year = {2022}
}
@article{Yacchirema2018,
abstract = {Obtrusive sleep apnea (OSA) is one of the most important sleep disorders because it has a direct adverse impact on the quality of life. Intellectual deterioration, decreased psychomotor performance, behavior, and personality disorders are some of the consequences of OSA. Therefore, a real-time monitoring of this disorder is a critical need in healthcare solutions. There are several systems for OSA detection. Nevertheless, despite their promising results, these systems not guiding their treatment. For these reasons, this research presents an innovative system for both to detect and support of treatment of OSA of elderly people by monitoring multiple factors such as sleep environment, sleep status, physical activities, and physiological parameters as well as the use of open data available in smart cities. Our system architecture performs two types of processing. On the one hand, a pre-processing based on rules that enables the sending of real-time notifications to responsible for the care of elderly, in the event of an emergency situation. This pre-processing is essentially based on a fog computing approach implemented in a smart device operating at the edge of the network that additionally offers advanced interoperability services: technical, syntactic, and semantic. On the other hand, a batch data processing that enables a descriptive analysis that statistically details the behavior of the data and a predictive analysis for the development of services, such as predicting the least polluted place to perform outdoor activities. This processing uses big data tools on cloud computing. The performed experiments show a 93.3% of effectivity in the air quality index prediction to guide the OSA treatment. The system's performance has been evaluated in terms of latency. The achieved results clearly demonstrate that the pre-processing of data at the edge of the network improves the efficiency of the system.},
author = {Yacchirema, Diana C. and Sarabia-Jacome, David and Palau, Carlos E. and Esteve, Manuel},
doi = {10.1109/ACCESS.2018.2849822},
issn = {21693536},
journal = {IEEE Access},
keywords = {Internet-of-Things,big data,cloud computing,fog computing,health monitoring,interoperability,open data,sleep monitoring},
pages = {35988--36001},
title = {{A smart system for sleep monitoring by integrating IoT with big data analytics}},
volume = {6},
year = {2018}
}
@inproceedings{10.1145/3297663.3310302,
abstract = {The proliferation of big data processing platforms has led to radically different system designs, such as MapReduce and the newer Spark. Understanding the workloads of such systems facilitates tuning and could foster new designs. However, whereas MapReduce workloads have been characterized extensively, relatively little public knowledge exists about the characteristics of Spark workloads in representative environments. To address this problem, in this work we collect and analyze a 6-month Spark workload from a major provider of big data processing services, Databricks. Our analysis focuses on a number of key features, such as the long-term trends of reads and modifications, the statistical properties of reads, and the popularity of clusters and of file formats. Overall, we present numerous findings that could form the basis of new systems studies and designs. Our quantitative evidence and its analysis suggest the existence of daily and weekly load imbalances, of heavy-tailed and bursty behaviour, of the relative rarity of modifications, and of proliferation of big data specific formats.},
address = {New York, NY, USA},
author = {Talluri, Sacheendra and Abad, Cristina L. and {\L}uszczak, Alicja and Iosup, Alexandru},
booktitle = {ICPE 2019 - Proceedings of the 2019 ACM/SPEC International Conference on Performance Engineering},
doi = {10.1145/3297663.3310302},
isbn = {9781450362399},
keywords = {apache spark,big data,characterization,cloud storage,file formats,interarrival time,long-term trend,popularity},
pages = {33--44},
publisher = {Association for Computing Machinery},
series = {ICPE '19},
title = {{Characterization of a big data storage workload in the cloud}},
url = {https://doi.org/10.1145/3297663.3310302},
year = {2019}
}
@article{Izquierdo2019120,
abstract = {The present study proposes an innovative educational methodology for elementary school kids that want to learn chess by using a mobile application which applies the augmented reality technique as a mechanism of reinforcement in Primary School. Interest in learning is encouraged when appropriate technological devices are involved. For this reason, digital education arouses motivation to learn, especially at an early age, when kids begin their academic training with creative initiatives using accessible applications for every subject. However, in Ecuador there are no applications created with augmented reality to strengthen and encourage the learning of chess. With this concept arrives “Jaque Maitte”, which is a mobile application, that uses a dynamic learning technique called Gamification. It achieves the learning of chess, with various methods of application for education, giving precise information about learning in an interactive way.},
annote = {cited By 12},
author = {{Llerena Izquierdo}, Joe and {Robalino Alfonso}, Maitte and {Andina Zambrano}, Michael and {Grijalva Segovia}, Jamilette},
issn = {16469895},
journal = {RISTI - Revista Iberica de Sistemas e Tecnologias de Informacao},
keywords = {Augmented Reality,Big Data,Digital Education,Interactive Systems,M-Learning},
number = {E22},
pages = {120--133},
publisher = {Associacao Iberica de Sistemas e Tecnologias de Informacao},
title = {{Mobile application to encourage education in school chess students using augmented reality and m-learning.}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075314406&partnerID=40&md5=f074d3efd1d1712f773afaf21dab7806},
volume = {2019},
year = {2019}
}
@article{Martinez-Mosquera2019215,
abstract = {This article describes research regarding Big Data integration in e-government decision-making, for instance, in areas such as solar energy provisioning, environmental protection, agricultural and natural resources exploitation, health and social care, education, housing and transportation management, among others. These studies refer to regions that have integrated Big Data in e-government, where South America is still in the early adoption stages. Hence, this study proposes three stepping-stones for Big Data integration in e-government decision-making: production, management and application. The proposed framework aims to be a reference in South America for Big Data adoption in e-government and, thus, help to mitigate the technology delay regarding other regions. Finally, the article presents a case study with open data obtained from the Instituto Nacional de Estad{\'{i}}stica y Censos of Ecuador (Ecuadorian Statistics and Census Agency).},
annote = {cited By 1},
author = {Martinez-Mosquera, Diana and Luj{\'{a}}n-Mora, Sergio},
doi = {10.15446/dyna.v86n209.77902},
file = {:C\:/Users/avile/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Martinez-Mosquera, Luj{\'{a}}n-Mora - 2019 - Framework for big data integration in e-government.pdf:pdf;:C\:/Users/avile/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Martinez-Mosquera, Luj{\'{a}}n-Mora - 2019 - Framework for big data integration in e-government(2).pdf:pdf},
issn = {00127353},
journal = {DYNA (Colombia)},
keywords = {Big data,E-government,Framework,Integration,Reference},
number = {209},
pages = {215--224},
publisher = {Universidad Nacional de Colombia},
title = {{Framework for big data integration in e-government}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074391206&doi=10.15446%2Fdyna.v86n209.77902&partnerID=40&md5=44e3d8783e991da3a0a55713524253d0},
volume = {86},
year = {2019}
}
@article{Paucar-Carrión2023459,
abstract = {This big data is the basis for creating new strategies by understanding that the value of data and the information extracted from it is the new gold mine. The objective of this article is to determine the contents and practices of big data that the academy has included, identifying the characteristics for the implementation of an academic plan with emphasis on the linkage of big data in the careers of journalism and social communication. This work integrates the quantitative and qualitative methods, developed for the use of big data in the communication field; the undergraduate academic offerings and curriculum were analyzed to determine the subjects related to big data. The result shows that journalism has at its disposal a number of digital tools, and their use is not optional in journalistic work; big data allows the technological processing of large volumes of data.},
annote = {cited By 0; Conference of International Conference on Communication and Applied Technologies, ICOMTA 2022 ; Conference Date: 7 September 2022 Through 9 September 2022; Conference Code:286689},
author = {{Paucar Carri{\'{o}}n}, Katty Yadira and Aguaded-G{\'{o}}mez, I. and Suing, A.},
doi = {10.1007/978-981-19-6347-6_41},
editor = {{Lopez-Lopez P.C. Torres-Toukoumidis A.}, De-Santis A Aviles O Barredo D},
isbn = {9789811963469},
issn = {21903026},
journal = {Smart Innovation, Systems and Technologies},
keywords = {Academia,Big data,Communication,Data journalism,University Education},
pages = {459--468},
publisher = {Springer Science and Business Media Deutschland GmbH},
title = {{Big Data in Ecuadorian Universities}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144213570&doi=10.1007%2F978-981-19-6347-6_41&partnerID=40&md5=774857b39da86a538332472f139372f4},
volume = {318},
year = {2023}
}
@inproceedings{Bonilla2018a,
abstract = {As the Internet of Things (IoT) grows, the attacks to these devices continue to increase, both in number and impact. We identify the requirements for a real-time data processing framework that can be used to detect attacks while they occur, and propose an architecture that would implement these requirements. The proposed framework can be used by vendors, thirdparty organizations, and end-users to provide on-line monitoring and real-time attack mitigation. Finally, we identify the research challenges that we will face when implementing this architecture.},
author = {Bonilla, Rafael I. and Abad, Cristina L.},
booktitle = {Proceedings - 2017 IEEE 15th International Conference on Dependable, Autonomic and Secure Computing, 2017 IEEE 15th International Conference on Pervasive Intelligence and Computing, 2017 IEEE 3rd International Conference on Big Data Intelligence and Compu},
doi = {10.1109/DASC-PICom-DataCom-CyberSciTec.2017.122},
isbn = {9781538619551},
keywords = {Anomaly detection,Attack detection,Cloud architecture,Distributed processing,IDS,IoT,Stream processing},
pages = {699--703},
title = {{Towards a real time framework for monitoring IoT devices for attack detection: Vision paper}},
volume = {2018-Janua},
year = {2018}
}
@conference{Molina-Granja2022,
abstract = {With the advancement of communications, the information and communication technologies sector has developed rapidly in recent years, governmental and non-governmental organizations require qualified personnel with knowledge of computer techniques and tools for handling new computing technologies, information processing, computer control and security, professionals who can incorporate Big Data, data analytics into organizations and facilitate decision-making at the executive and managerial level. The present work aims to respond to the following research objective: "Determine the demand and employability of the creation of the Data Science Engineering career in Ecuador", for which, through a survey applied to the educational institutions of the center of the country, using virtual resources, 4,210 responses were obtained from students and 81 responses from public and private institutions; From the resulting analysis, the objective is fully met with a favorable trend to justify the creation of the Data Science Engineering career in Ecuador.},
annote = {cited By 0; Conference of 17th Iberian Conference on Information Systems and Technologies, CISTI 2022 ; Conference Date: 22 June 2022 Through 25 June 2022; Conference Code:181005},
author = {Molina-Granja, Fernando and Barba-Maggi, Lida and Molina-Valdiviezo, Lorena and Bustamante-Granda, Wayner},
booktitle = {Iberian Conference on Information Systems and Technologies, CISTI},
doi = {10.23919/CISTI54924.2022.9820496},
editor = {{Rocha A. Bordel B.}, Penalvo F G Goncalves R},
isbn = {9789893334362},
issn = {21660735},
keywords = {Data analytics,Data science,Demand and employability,Undergraduate career},
publisher = {IEEE Computer Society},
title = {{Demand and employability study of the data science engineering career in Ecuador}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134802184&doi=10.23919%2FCISTI54924.2022.9820496&partnerID=40&md5=0dc9d4dfd59566ac2cecbfb1542b4f4f},
volume = {2022-June},
year = {2022}
}
@article{Garcia-Velez2019,
abstract = {Universities in Latin America commonly gather much more information about their students than allowed by data protection regulations in other parts of the world. We have tackled the question of whether abundant socio-economic data can be harnessed for the purpose of predicting academic outcomes and, thereby, taking proactive actions in student attention, course planning and resource management. A study was conducted to analyze the data gathered by a private university in Ecuador over more than 20 years, to normalize them and to parameterize a Multi-Layer Perceptron neural network, whose best-performing configuration would be used as a benchmark for the comparison of more recent and sophisticated Artificial Intelligence techniques. However, an extensive scan of hyperparameters for the perceptron-exploring more than 12,000 configurations-revealed no significant relationships between the input variables and the chosen metrics, suggesting that there is no gain from processing the extensive socio-economic data. This finding contradicts the expectations raised by previous works in the related literature and in some cases highlights important methodological flaws.},
address = {Research Group of Artificial Intelligence and Assistance Technology (GIIATA), Universidad Polit{\'{e}}cnica Salesiana, Cuenca, 010102, Ecuador},
annote = {Cited By :2

Export Date: 23 March 2023

Correspondence Address: L{\'{o}}pez-Nores, M.; AtlantTIC Research Center, Spain; email: mlnores@det.uvigo.es},
author = {Garc{\'{i}}a-V{\'{e}}lez, Roberto Agust{\'{i}}n and L{\'{o}}pez-Nores, Mart{\'{i}}n and Gonz{\'{a}}lez-Fern{\'{a}}ndez, Gabriel and Robles-Bykbaev, Vladimir Espartaco and Wallace, Manolis and Pazos-Arias, Jos{\'{e}} J. and Gil-Solla, Alberto},
doi = {10.3390/app9153084},
issn = {20763417},
journal = {Applied Sciences (Switzerland)},
keywords = {Data protection,Deep learning,Multi-Layer Perceptron,Performance prediction,Student records},
language = {English},
number = {15},
publisher = {MDPI AG},
title = {{On data protection regulations, big data and sledgehammers in Higher Education}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070723081&doi=10.3390%2Fapp9153084&partnerID=40&md5=5726174beb251391db343da704c5dafb},
volume = {9},
year = {2019}
}
@inproceedings{10.1145/3322645.3322668,
abstract = {New enterprises face several challenges in keeping their customers and keeping up with the dynamic growth of services and products. On the other hand, enterprises are generating Petabytes of data and managers don't know how to use this invaluable data. Some big enterprises are growing quickly because of the right use of information as a key factor in their decision-making and market intelligence. Business is developing rapidly and in unpredictably. The rapid evolution of the Internet is opening up opportunities to create new kinds of business like e-business, smart factories, and virtual enterprises (VE). In this context, based on Enterprise Architecture (EA), VE, and synergy in business integration, we propose to develop a research framework, which details the formal process to achieve a fluid business synergy in business collaboration processes. The proposal consists of a conceptual model with three factors: EA, VE, and Synergy in Business Integration and Collaboration (BIC).},
address = {New York, NY, USA},
author = {Lopez, Cindy Pamela and Segura, Marco and Sant{\'{o}}rum, Marco},
booktitle = {ACM International Conference Proceeding Series},
doi = {10.1145/3322645.3322668},
isbn = {9781450361033},
keywords = {Business Synergy,Collaboration,Enterprise Architecture,Integration,Ontology,Virtual organization},
pages = {125--129},
publisher = {Association for Computing Machinery},
series = {ICISS '19},
title = {{Framework to develop a business synergy through enterprise architecture}},
url = {https://doi.org/10.1145/3322645.3322668},
volume = {Part F1483},
year = {2019}
}
@inproceedings{Carrillo2018,
abstract = {We consider the problem of evaluating new improvements to distributed processing platforms like Spark and Hadoop. One approach commonly used when evaluating these systems is to use workloads published by companies with large data clusters, like Google and Facebook. These evaluations seek to demonstrate the benefits of improvements to critical framework components like the job scheduler, under realistic workloads. However, published workloads typically do not contain information on dependencies between the jobs. This is problematic, as ignoring dependencies could lead to significantly misestimating the speedup obtained from a particular improvement. In this position paper, we discuss why it is important to include job dependency information when evaluating distributed processing frameworks, and show that workflow mining techniques can be used to obtain dependencies from job traces that lack them. As a proof-of-concept, we show that the proposed methodology is able to find workflows in traces published by Google.},
author = {Carrillo, Gladys E. and Abad, Cristina L.},
booktitle = {Proceedings - 2017 IEEE 15th International Conference on Dependable, Autonomic and Secure Computing, 2017 IEEE 15th International Conference on Pervasive Intelligence and Computing, 2017 IEEE 3rd International Conference on Big Data Intelligence and Compu},
doi = {10.1109/DASC-PICom-DataCom-CyberSciTec.2017.168},
isbn = {9781538619551},
keywords = {Clusters,Data mining,Distributed processing,Hadoop,Workflows,Workloads},
pages = {1025--1030},
title = {{Inferring workflows with job dependencies from distributed processing systems logs: (Or, how to evaluate your systems with realistic workflows NOT pulled out of thin air)}},
volume = {2018-Janua},
year = {2018}
}
@inproceedings{10.1145/3274250.3274263,
abstract = {The use of the web as a universal communication platform generates large volumes of data (Big data), which in many cases, need to be processed so that they can become useful knowledge in face of the sceptics who have doubts about the credibility of such information. The use of web data that comes from educational contexts needs to be addressed, since that large amount of unstructured information is not being valued, losing valuable information that can be used. To solve this problem, we propose the use of data mining techniques such as sentiment analysis to validate the information that comes from the educational platforms. The objective of this research is to propose a methodology that allows the user to apply sentiment analysis in a simple way, because although some researchers have done it, very few do with data in the educational context. The results obtained prove that the proposal can be used in similar cases.},
address = {New York, NY, USA},
author = {Pe{\~{n}}afiel, Myriam and V{\'{a}}squez, Stefanie and V{\'{a}}squez, Diego and Zaldumbide, Juan and Luj{\'{a}}n-Mora, Sergio},
booktitle = {ACM International Conference Proceeding Series},
doi = {10.1145/3274250.3274263},
isbn = {9781450365383},
keywords = {Data mining,Educational data,Method,Opinion mining,Sentiment analysis,Text mining},
pages = {74--78},
publisher = {Association for Computing Machinery},
series = {ICoMS '18},
title = {{Data mining and opinion mining: A tool in educational context}},
url = {https://doi.org/10.1145/3274250.3274263},
year = {2018}
}
@article{Marcos2021181,
abstract = {Solar radiation and wind data play an important role in renewable energy projects to produce electricity. In Ecuador, these data are not always available for locations of interest due to absences of meteorological stations. In the scope of this paper, a low-cost automatic meteorological station prototype based on Raspberry technology was developed to measure the aforementioned variables. The objective of this paper is twofold: a) to present a proposal for the design of a low-cost automatic weather station using the Raspberry Pi microcomputer, showing the feasibility of this technology as an alternative for the construction of automatic meteorological station and; b) to use Forecasting with neural networks to predict solar radiation in Manta, Ecuador, based on the historical data collected: solar radiation, wind speed and wind direction. We proved that both technology feasibility and Machine learning has a high potential as a tool to use in this field of study.},
annote = {cited By 1; Conference of 7th Annual International Conference on Information Management and Big Data, SIMBig 2020 ; Conference Date: 1 October 2020 Through 3 October 2020; Conference Code:260449},
author = {{Ponce Jara}, Marcos and Talavera, Alvaro and Vel{\'{a}}squez, Carlos and {Tonato Peralta}, David},
doi = {10.1007/978-3-030-76228-5_13},
editor = {{Lossio-Ventura J.A. Valverde-Rebaza J.C.}, Diaz E Alatrista-Salas H},
isbn = {9783030762278},
issn = {18650937},
journal = {Communications in Computer and Information Science},
keywords = {Neural networks,Solar radiation,Weather station,Wind speed},
pages = {181--194},
publisher = {Springer Science and Business Media Deutschland GmbH},
title = {{Prediction of Solar Radiation Using Neural Networks Forecasting}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111123223&doi=10.1007%2F978-3-030-76228-5_13&partnerID=40&md5=059a777a26946cf62f5f0bcaadeff83f},
volume = {1410 CCIS},
year = {2021}
}
@article{Jimenez2020182,
abstract = {The techniques for downscaling climatic variables are essential to support tools for water resources planning and management in a climate change context in the entire world. Support vector machines (SVM) through regression approach (SVR), constitute an artificial intelligence method to downscaling climatic variables. Since that statistical downscaling based on regression methodologies is susceptible to the predictor variables, the aim of this study was exploring a big database of predictor variables to achieve the best performance of a statistical downscaling model using SVR to predict precipitation and temperature future projections. Data from regional climate models of Ecuador and information of three meteorological stations was used to apply this approach in the Tomebamba river sub-basin, located in southern Ecuadorian Andean region. The results show that the downscaling model has a better performance with the climatic averages. The precipitation extremes do not estimate in a good manner, but the model achieves an effective behavior with the temperature extremes values. These results could serve to improve water balance projections in the future for formulating suitable measures for climate change decision-making.},
annote = {cited By 2; Conference of 6th Conference on Information and Communication Technologies, TIC.EC 2019 ; Conference Date: 27 November 2019 Through 29 November 2019; Conference Code:234179},
author = {Jimenez, Stalin and Aviles, Alex and Gal{\'{a}}n, Luciano and Flores, Andr{\'{e}}s and Matovelle, Carlos and Vintimilla, Cristian},
doi = {10.1007/978-3-030-35740-5_13},
editor = {{Fonseca C E. Rodriguez Morales G.}, Orellana Cordero M Botto-Tobar M Crespo Martinez E Patino Leon A},
isbn = {9783030357399},
issn = {21945365},
journal = {Advances in Intelligent Systems and Computing},
keywords = {Andean basin,Artificial intelligence,Climate big data,Climate change,SVR,Statistical downscaling},
pages = {182--193},
publisher = {Springer},
title = {{Support Vector Regression to Downscaling Climate Big Data: An Application for Precipitation and Temperature Future Projection Assessment}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076524642&doi=10.1007%2F978-3-030-35740-5_13&partnerID=40&md5=260f8d422d291ad6e509ed5401f745fb},
volume = {1099},
year = {2020}
}
@inproceedings{Astudillo2020,
abstract = {Data Analytic (DA) is currently a very important approach to obtain the best possible benefit of the data, but its degree of difficulty compared to other computational processes limits its implementation in organizations. In addition, it remains a term highly confused with respect to other areas of data science, such as data mining, and Big Data. There are few methodologies for its implementation, in addition, its complexity makes it non-participatory, with a certain degree of resistance on the part of the users. The knowledge and skills of users must be exploited when analyzing and producing the business intelligence necessary for the Data Analytic execution. In this position paper, we explore the possibilities of contribution through a Methodology for Data Analytic, which is extended with the incorporation of features extracted from a user-centered design (UCD) approach inspired by the ISEA methodology. This existing DA methodology, called MIDANO, will be extended using gamification techniques, to facilitate the applicability and understanding, in order to guarantee a participation of organizational actors, resulting in a Participatory Data Analytic Methodology.},
author = {Astudillo, Boris and Sant{\'{o}}rum, Marco and Aguilar, Jose},
booktitle = {2020 7th International Conference on eDemocracy and eGovernment, ICEDEG 2020},
doi = {10.1109/ICEDEG48599.2020.9096790},
isbn = {9781728158822},
keywords = {data analytics,data science,gamification,user-centered design},
pages = {237--242},
title = {{A methodology for Data Analytic Based on Organizational Characterization through a User-centered Design: A Position Paper}},
year = {2020}
}
@conference{ToapantaToapanta2020258,
abstract = {Were analyzed the implementation of a Blockchain model for the national public data system. The problem is the lack of a data query architecture and administrative procedures. The objective is to perform an analysis of the Blockchain to apply into a process in the National Public Data System for Ecuador. It was applied the deductive method and exploratory research were applied to analyze the information in the reference articles. It turned out the following: Conceptual Model of National Data System, Mixed Architecture and Security Algorithm. It was concluded that the application of a Blockchain system in the national system of public data would benefit public entities and citizens; all participants will have better data security and better efficiency in the procedures requested by citizens and other public entities. {\textcopyright} 2020 IEEE.},
annote = {cited By 2; Conference of 3rd International Conference on Information and Computer Technologies, ICICT 2020 ; Conference Date: 9 March 2020 Through 12 March 2020; Conference Code:159731},
author = {Toapanta, Segundo Mois{\'{e}}s and {Mafla Gallegos}, Luis Enrique and {Ordo{\~{n}}ez Baldeon}, P and {Trivino Trivino}, F D},
booktitle = {Proceedings - 3rd International Conference on Information and Computer Technologies, ICICT 2020},
doi = {10.1109/ICICT50521.2020.00046},
file = {:C\:/Users/avile/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Toapanta Toapanta et al. - 2020 - Blockchain Analysis Applied to a Process for the National Public Data System for Ecuador.pdf:pdf;:C\:/Users/avile/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Toapanta Toapanta et al. - 2020 - Blockchain Analysis Applied to a Process for the National Public Data System for Ecuador(2).pdf:pdf},
isbn = {9781728172835},
keywords = {Administrative procedures,Architecture and secur,Blockchain,National security},
pages = {258--265},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Blockchain analysis applied to a process for the national public data system for Ecuador}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085574246&doi=10.1109%2FICICT50521.2020.00046&partnerID=40&md5=6edd905ad7f86f2173b258568251b768},
year = {2020}
}
@article{Cuenca2022222,
abstract = {Social networks in operational and strategic management by members of military forces are essential for communication purposes. Innovation and technological revolution are generating more significant interaction between military entities and citizens. There is considerable potential in using social networks as public management tools to develop a multidirectional communication space. This article presents the results of an exploratory study to members of the Ecuadorian Land Forces to understand the use, impact, and incidence generated in the publications published through social networks. Also, the economic impact of this interaction in networks on a monthly and annual level is measured. The results indicate that there is interest in the information disseminated through official accounts; however, the levels of engagement are low, indicating opportunities and challenges for optimizing social media.},
annote = {cited By 0; Conference of 16th Multidisciplinary International Congress on Science and Technology, CIT 2021 ; Conference Date: 14 June 2021 Through 18 June 2021; Conference Code:272029},
author = {Cuenca, V{\'{i}}ctor and Urbina, Myriam and C{\'{o}}rdova, Arcenio and Cuenca, Erick},
doi = {10.1007/978-3-030-96046-9_17},
editor = {{Botto-Tobar M. Cruz H.}, Diaz Cadena A Durakovic B},
isbn = {9783030960452},
issn = {23673389},
journal = {Lecture Notes in Networks and Systems},
keywords = {Big Data,Economic,Management,Military force,Social networks},
pages = {222--233},
publisher = {Springer Science and Business Media Deutschland GmbH},
title = {{Use of Social Networks in Operational and Strategic Management: The Case of the Ecuadorian Land Force}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125403847&doi=10.1007%2F978-3-030-96046-9_17&partnerID=40&md5=60703ff6af6ae9f1c1d80e33b95df191},
volume = {406 LNNS},
year = {2022}
}
@inproceedings{Correa2018,
abstract = {The present work warns of the potential performance of the mapreduce technique for handling big data from the intelligent measurement of electrical energy, this information is managed by the measurement data management system and is used to find the energy consumption pattern of the users. The large amount of information from the intelligent measurement of electrical energy requires a short-term analysis for a subsequent decision-making required to obtain the answer to the demand of the energy in each electric distribution company. In this way, this work presents a technique to handle a large amount of information in a short time to generate trends and statistics of electric energy consumption information from the information coming from several years of information storage.},
author = {Correa, Estuardo and Inga, Esteban and Inga, Juan and Hincapie, Roberto},
booktitle = {Proceedings - 2017 International Conference on Information Systems and Computer Science, INCISCOS 2017},
doi = {10.1109/INCISCOS.2017.19},
isbn = {9781538626443},
keywords = {big data,mapreduce,meter data management system (MDMS),smart grid,smart metering},
pages = {334--339},
title = {{Electrical consumption pattern base on meter data management system using big data techniques}},
volume = {2017-Novem},
year = {2018}
}
@conference{Toapanta2019147,
abstract = {We analyzed a part of the global ecosystem and massive data known as Internet of Things and Big Data respectively, with theoretical or applied security models. The problem is the introduction of solutions in public security, user privacy and cybernetic coercion, to deliver trusted services for data generated from public networks. The objective is to define a prototype of security model applied to Internet of Things with Big Data for tourism management in cities of Ecuador. Were applied the deductive method and the exploration to examine the information of the referenced researches. It turned out the following: Architecture prototype for the tourism management, Security model applied to architecture, Flowchart for the management of tourism information and Formula of lost packages. It was concluded that a data security strategy is necessary through a correct routing, reliable and high availability that allows to increase its level of reliability; also have a captive portal by sectors, which allows us to generate confidentiality agreements to guarantee the privacy of data; the model should be considered at the country level for a standard management of tourist information.},
annote = {cited By 1; Conference of 3rd World Conference on Smart Trends in Systems, Security and Sustainability, WorldS4 2019 ; Conference Date: 30 July 2019 Through 31 July 2019; Conference Code:154926},
author = {Toapanta, Segundo Mois{\'{e}}s and {Hern{\'{a}}ndez Romero}, Hugo Xavier and {Mora Saltos}, Nelson Salom{\'{o}}n and {Mafla Gallegos}, Luis Enrique},
booktitle = {Proceedings of the 3rd World Conference on Smart Trends in Systems, Security and Sustainability, WorldS4 2019},
doi = {10.1109/WorldS4.2019.8904016},
editor = {{Yang X.-S. Dey N.}, Joshi A},
isbn = {9781728137803},
keywords = {Big Data,Cities of Ecuador,Internet of Things,Security Model,Tourism Management},
pages = {147--152},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Prototype of a security model applied to IoT with big data for tourist management in the cities of Ecuador}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075892944&doi=10.1109%2FWorldS4.2019.8904016&partnerID=40&md5=9aa04344c83311362dbeae9a8e2820e6},
year = {2019}
}
@article{BaldeonEgas2020419,
abstract = {Currently, data analysis in higher education institutions is not a luxury, it is a necessity. The large amounts of data generated through university academic functions are the main reason for an analysis and representation of these; since they will allow an adequate decision making in the university academic processes. In this work we propose to perform an analysis of the data generated in the Israel Technological University from Ecuador in the period 2012–2018; for this we apply Data mining algorithms to make suitable predictions and by using data visualization techniques to represent this information allowing us to easily understand it; as a result, relevant information is obtained that will allow the personnel in charge to make the appropriate decisions and improve the processes that have low percentages.},
annote = {cited By 1; Conference of 1st International Conference on Advances in Emerging Trends and Technologies, ICAETT 2019 ; Conference Date: 29 May 2019 Through 31 May 2019; Conference Code:233339},
author = {{Baldeon Egas}, Paul Francisco and {Gaibor Saltos}, Miguel Alfredo and Toasa, Renato},
doi = {10.1007/978-3-030-32022-5_39},
editor = {{Botto-Tobar M. Leon-Acurio J.}, Diaz Cadena A Montiel Diaz P},
file = {:C\:/Users/avile/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Baldeon Egas, Gaibor Saltos, Toasa - 2020 - Application of Data Mining and Data Visualization in Strategic Management Data at Israel Tec.pdf:pdf;:C\:/Users/avile/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Baldeon Egas, Gaibor Saltos, Toasa - 2020 - Application of Data Mining and Data Visualization in Strategic Management Data at Israel (2).pdf:pdf},
isbn = {9783030320218},
issn = {21945365},
journal = {Advances in Intelligent Systems and Computing},
keywords = {Data mining,Higher education,Strategic management,Visualization},
pages = {419--431},
publisher = {Springer Science and Business Media Deutschland GmbH},
title = {{Application of Data Mining and Data Visualization in Strategic Management Data at Israel Technological University of Ecuador}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075685222&doi=10.1007%2F978-3-030-32022-5_39&partnerID=40&md5=b4bff6b2a58a7051e147a75b7694d371},
volume = {1066},
year = {2020}
}
@article{Quelal2018334,
abstract = {Big data has become a subject of great interest among a variety of organizations, both from the scientific and business sectors. In this line, it is important to know the focus of attention that companies have on big data. This paper presents a study conducted in Ecuador about big data initiatives among large and medium companies. Results indicate that companies do not have a clear understanding of the implications of big data for their own benefits. Also, higher interest on big data initiatives comes from the private rather than the public sector. And, companies have a preference for contracting big data services from third-parties instead of hiring specialized personnel.},
annote = {cited By 0; Conference of 7th International Congress on Big Data, BigData 2018 Held as Part of the Services Conference Federation, SCF 2018 ; Conference Date: 25 June 2018 Through 30 June 2018; Conference Code:214839},
author = {Quelal, Rosa and Villavicencio, Monica},
doi = {10.1007/978-3-319-94301-5_27},
editor = {{Khan L. Zhang L.}, Lee K Chin F Y Chen C L},
isbn = {9783319943008},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Big data,Ecuador,Large companies,Survey},
pages = {334--342},
publisher = {Springer Verlag},
title = {{A survey of big data use in large and medium Ecuadorian companies}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049364951&doi=10.1007%2F978-3-319-94301-5_27&partnerID=40&md5=3d26c9828e4197008349c7c307a82a72},
volume = {10968 LNCS},
year = {2018}
}
@inproceedings{Nicolalde2018,
abstract = {The Internet of Things (IoT) is an evolution of the current Internet in a ubiquitous network of interconnected devices. The continuous transmission of raw data flows by these devices to the IoT network is voluminous, generating terabytes of data continuously. However, the analysis of this massive data requires many efforts at multiple levels for the extraction of knowledge and decision making. Therefore, Big Data Analysis is a current area of research and development that has become increasingly important. This article investigates the potential impact of major data challenges, cutting-edge research efforts aimed at analyzing IoT data, and various tools associated with its analysis. As a result, this article suggests the use of platforms to explore Big Data in numerous stages and to better understand the knowledge we can draw from the data, which opens a new horizon for researchers to develop solutions based on open research challenges and topics.},
author = {{Constante Nicolalde}, Fabian and Silva, Fernando and Herrera, Boris and Pereira, Antonio},
booktitle = {Iberian Conference on Information Systems and Technologies, CISTI},
doi = {10.23919/CISTI.2018.8399297},
isbn = {9789899843486},
issn = {21660735},
keywords = {Big Data Analytics,Hadoop,Internet of Things,Massive data,Structured data,Unstructured Data},
pages = {1--6},
title = {{Big Data analysis tools in IoT and their challenges in open researches}},
volume = {2018-June},
year = {2018}
}
@inproceedings{Gonzalez-Jaramillo2016,
abstract = {Some years ago we used to talk about a very far future, a dream in where people can access to services and information into small devices; in which we can accesses to information, make calls, watch videos and surf maps. That far future is not so far, actually the advance of technology involves a more powerful hardware which is day to day is becoming into small devices with big resources [14]. The upcoming development of electronic allows that these devices could be integrated into smart networks [8]; these networks are called Wireless Sensor Networks (WSN; [13]). WSN do not need physical connections, they use communication systems such as ZigBEE, WiFi, Bluetooth, GSM [7]. Each individual device called moth have autonomous characteristics of communications, storage of data, automatic organization and recovery of the network communication among others that allow the network performs an autonomous work, with the possibility of Internet connection. These characteristic let emerge the so called Internet of Things (IoT), phrase that was coined in the early 1990's, where everyday objects have network connectivity, allowing them to send and receive data [1]. Since these days, technology has an exponential advance and now it is possible to find devices that permit earth observations in real time [11,15,4]. All this collected information use cloud and no-cloud storage [3]. These systems allow to store big amounts of data [6], that is collected from devices integrated in the concept of IoT [5] (especially incomes from smartphones, GPS's devices and various earth observation sensors). The analysis of this big data (some of them spatial information) will be helpful in treatment and finding related solutions in specific areas such as public administration, environment, urban services, etc. [12]. Also, the data that at the beginning was depicted like sparse information, it begins to converge into a shape. This shape can be seen like maps that could be paper maps or digital ones. The representation of the information into maps is linked to a wide range of disciplines and the concept is not new but the enhancement that it has reached until now is incredible, especially the digital information given in Internet which could be accessed by electronic devices (smart phones, tablets and computers). E-government services would improve efficiency and consequently citizen's satisfaction due to the implementation of Spatial Data Infrastructure (SDI, [9]). In order to good development of SDI, the Open Geospatial Consortium (OCG) has an important role. OGC is an international industry consortium of companies, government agencies and universities participating in a consensus process to develop publicly available interface standards [10]. One of the most popular OGC standards is the Web Map Service (WMS) that allows to show spatial information, considered fundamental for the development of many of the services in the way that a citizen can access to e-government services (e.g., cadastre, [2]) and e-democracy. In this talk, the objective is to introduce some concepts considered essential in the development of the modern society and smart cities. Concepts such as IoT, big data and mapping not only allow the collection or merely visualization of information; these promote the enhancement of access to e-services, also they could be used to face challenges that a good administration of the limited resources implies.},
author = {Gonzalez-Jaramillo, Victor H.},
booktitle = {2016 Third International Conference on eDemocracy & eGovernment (ICEDEG)},
doi = {10.1109/ICEDEG.2016.7461464},
isbn = {978-3-9075-8911-3},
keywords = {Big data,Earth,Geographic information systems,Internet of things,Sensors,Smart cities,Wireless sensor networks},
month = {mar},
pages = {5--6},
publisher = {IEEE},
title = {{Tutorial: Internet of Things and the upcoming wireless sensor networks related with the use of big data in mapping services; issues of smart cities}},
url = {http://ieeexplore.ieee.org/document/7461464/},
volume = {2016-Janua},
year = {2016}
}
@inproceedings{Pena2020,
abstract = {This research assesses the health conditions of the people in the study and determines the reason why a person dies after being infected with COVID-19. In this study, 538 sample groups that provided medical data from people in different locations were analyzed. The biggest challenge in this study was to carry out 2 different criteria within the same data set to conclude that the mortality of the persons inside a group depends more than anything on the age of the person at risk and the presence of one or more other health disorders of the primary disease, which in this case is COVID-19. For this study, the public data set 'COVID analytics' was used, which provided all the necessary medical information and the classification of the groups, which are then interpreted as useful labels to better deduce the degree of mortality of the affected person. After completing the data analysis, it is determined that the factors that aggravate the condition of a patient with COVID-19 are: hypertension, advanced age and any other disease.},
author = {Pena, Carlos and Peralta, Florencio and Hurtado, Remigio},
booktitle = {2020 IEEE International Autumn Meeting on Power, Electronics and Computing, ROPEC 2020},
doi = {10.1109/ROPEC50909.2020.9258683},
isbn = {9781728199535},
keywords = {Clustering,Covid-19,Linear regression,Multi-linear regression,Polynomial regression,Quadratic regression},
pages = {1--7},
title = {{Subgroup classification model identifying the most influential factors in the mortality of patients with COVID-19 using data analysis}},
volume = {4},
year = {2020}
}
@inproceedings{Andrade2019,
abstract = {Traditional security tools are based on predetermined signatures or rules that show rigidity in the face of the dynamics of the interconnections that occur in organizations. The inclusion of analytic in security systems extends the field of vision of security analysts for proactive threat detection. This allows SOC specialists to make decisions in real time and focus on the protection of critical assets of the organization. Our contribution in this work is to analyze the applicability of the use of Big Data as a complementary tool for the detection of security events in a real CSIRT environment, validating the architecture, configuration and visualization using the ELK stack as a Big Data platform.},
author = {Andrade, Roberto and Torres, Jenny},
booktitle = {2018 IEEE 9th Annual Information Technology, Electronics and Mobile Communication Conference, IEMCON 2018},
doi = {10.1109/IEMCON.2018.8614779},
isbn = {9781538672662},
keywords = {big data,cognitive security,cybersecurity,security operation center},
pages = {1076--1080},
title = {{Enhancing intelligence SOC with big data tools}},
year = {2019}
}
@inproceedings{Sacoto-Cabrera2022,
abstract = {Digital Transformation (TD) in different industry sectors, supported by tools such as the Internet of Things (IoT), Cloud Computing, Artificial Intelligence, Big Data, Data Analysis applications, enables the development of "smart"applications and solutions to serve the needs of society. The IoT market and cloud platform development have allowed us to provide a novel alternative to improve urban water management. We present a design and implementation of a framework for urban water management consisting of smart meters manufactured by the company TARPUQ and the development of an Advanced Metering Infrastructure System (AMI) for end devices control, registration, and billing of urban water service consumption. The results verified that the SMART-WATER pilot project, from the final devices to the AMI Platform, is a reliable support for the Digital Transformation of urban water measurement.},
author = {Sacoto-Cabrera, Erwin J. and Castillo, Ismael and Pauta, Wilson and Trelles, Paul and Tamariz, Pablo and Guambana, Leimer},
booktitle = {2022 IEEE ANDESCON},
doi = {10.1109/ANDESCON56260.2022.9989581},
isbn = {978-1-6654-8854-9},
keywords = {AMI-Platform,Internet-of-Things,LoRaWAN,smart metering,urban water measurement},
month = {nov},
pages = {1--6},
publisher = {IEEE},
title = {{Smart-Water: Digital Transformation of Urban Water Measurement}},
url = {https://ieeexplore.ieee.org/document/9989581/},
year = {2022}
}
@article{Zambrano-Asanza2023,
abstract = {The long-term distribution planning should include an understanding of consumer behavior and needs to develop strategic expansion alternatives that meet the future demand. The magnitude of growth along with the place where and when it will be developed are determined by the spatial load forecasting. Thus, this paper proposes a spatial-temporal load forecasting method to recognize and predict development patterns using historical dynamics and determine the development of consumers and electric load in small areas. An artificial neural network is integrated to a cellular automaton method to establish transition rules, based on land-use preferences, neighborhood states, spatial constraints, and a stochastic disturbance. The main feature is the incorporation of temporality, as well as taking advantage of geospatial-temporal data analytics to calibrate and validate a holistic and integral framework. Validation consists of measuring the spatial error pattern during the training and testing phase. The performance of the method is assessed in the service area of an Ecuadorian power utility. The knowledge extraction from large-scale data, evaluating the sensitivity of parameters and spatial resolution was carried out in reasonable times. It is concluded that adequate normalization and use of temporality in the spatial factors improve the error in the spatial-temporal load forecasting.},
annote = {cited By 0},
author = {Zambrano-Asanza, S. and Morales, R. E. and Montalvan, Joel A. and Franco, John F.},
doi = {10.1016/j.ijepes.2022.108906},
issn = {01420615},
journal = {International Journal of Electrical Power and Energy Systems},
keywords = {Artificial neural network,Big data analytic,Cellular automata,Distribution planning,Geospatial analysis,Spatial load forecasting},
publisher = {Elsevier Ltd},
title = {{Integrating artificial neural networks and cellular automata model for spatial-temporal load forecasting}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145022329&doi=10.1016%2Fj.ijepes.2022.108906&partnerID=40&md5=18d55c226988d32924b5f90c536467a7},
volume = {148},
year = {2023}
}
@inproceedings{Martinez-Mosquera2018,
abstract = {Big Data is a popular term used to define the storage and processing of high volumes of data. The main aim is to assist companies to make better business decisions. There is a lot of research about developing systems and techniques to deal with Big Data and, since a picture is worth a thousand words, the authors usually present diagrams of their proposals. There is, in this regard, a lack of a standardized format to model Big Data; thus, this paper intends to promote the use of the Unified Modeling Language (UML) for modeling Big Data scenarios. In this paper, the use of UML for modeling the extract process of Big Data is presented. UML is a standard that provides several useful elements for representing the main ideas during the design of a system. Some systems require certain concepts that are not covered by UML. For these cases, the metamodel of UML can be extended using a mechanism called stereotyping. In this paper, we propose five new stereotypes and the use of three others proposed in a previous research. To provide a better understanding, we have modeled three tools used in the Big Data extract process. The results state a format based on a standard.},
author = {Martinez-Mosquera, Diana and Luj{\'{a}}n-Mora, Sergio and Recalde, Henry},
booktitle = {Proceedings - 2017 International Conference on Information Systems and Computer Science, INCISCOS 2017},
doi = {10.1109/INCISCOS.2017.18},
isbn = {9781538626443},
keywords = {UML,big,data,extract,modeling},
pages = {207--211},
title = {{Conceptual modeling of big data extract processes with UML}},
volume = {2017-Novem},
year = {2018}
}
@inproceedings{Granda-Cantuna2018,
abstract = {This paper presents a Wireless Sensor Network (WSN) solution applied to Precision Agriculture (PA) capable of collecting real time data on different parameters related to agriculture. The technological advances related to this activity are of great importance since agriculture is considered an economic and social pillar essential for the wellbeing of society. In addition, the growing demand for real-time information in the agriculture field has driven the development of efficient wireless communications via sensor networks. WSN provides low cost, low energy consumption, easy to implement solution in places of difficult access for the implementation of wired networks. Precision agriculture is a way to optimize resources and improve cultivation through the collection of relevant information through the deployment of sensor networks, providing government authorities with statistical information to make appropriate decisions based on reliable data. The present research describes the design, implementation and validation process of a WSN technological solution which can collect information related to humidity, environment and soil temperature, atmospheric pressure, level of luminosity and UV radiation; this information is relevant to determine optimal parameters for cultivation and farming methods using IoT technologies for Big Data analysis at the government level.},
author = {Granda-Cantuna, Jorge and Molina-Colcha, Carlos and Hidalgo-Lupera, Sergio Enrique and Valarezo-Varela, Christian David},
booktitle = {2018 5th International Conference on eDemocracy and eGovernment, ICEDEG 2018},
doi = {10.1109/ICEDEG.2018.8372346},
isbn = {9781538625194},
keywords = {API,Big Data,EGovernment,IoT,Precision Agriculture,Wireless Sensor Network,Zigbee},
pages = {144--149},
title = {{Design and Implementation of a Wireless Sensor Network for Precision Agriculture Operating in API Mode}},
year = {2018}
}
@inproceedings{Foreman2017,
abstract = {Advanced Metering Infrastructure (AMI) have rapidly become a topic of international interest as governments have sponsored their deployment for the purposes of utility service reliability and efficiency, e.g., water and electricity conservation. Two problems plague such deployments. First is the protection of consumer privacy. Second is the problem of huge amounts of data from such deployments. A new architecture is proposed to address these problems through the use of Aggregators, which incorporate temporary data buffering and the modularization of utility grid analysis. These Aggregators are used to deliver anonymized summary data to the central utility while preserving billing and automated connection services.},
archivePrefix = {arXiv},
arxivId = {1607.06377},
author = {Foreman, James Christopher and Pacheco, Franklin E.},
booktitle = {2017 IEEE PES Innovative Smart Grid Technologies Conference - Latin America, ISGT Latin America 2017},
doi = {10.1109/ISGT-LA.2017.8126704},
eprint = {1607.06377},
isbn = {9781538633120},
keywords = {Advanced Metering Infrastructure,Aggregation,Architecture,Big Data,Privacy.},
pages = {1--5},
title = {{Aggregation architecture for data reduction and privacy in advanced metering infrastructure}},
volume = {2017-Janua},
year = {2017}
}
@inproceedings{Herrera2016,
abstract = {This research corresponds to a first phase of study on the search of the main causes that generate vehicular traffic in the Metropolitan District of Quito and approaching potential application I.3 through the use of intelligent systems based on social networks and sensorial data using Big Data. So the current situation of the city is analyzed as well as the problem that traffic represent for Quito, subsequently the analysis of various cases throughout the world who have suffered the problem of traffic congestion is summarized and then is analized and related with solutions that have been taken and which have improved mobility in these cities. While the focus of this study is not to provide direct solutions to the problem of transportation but rather to present the diagnosis of the main problems. The study deepens with field research with 95% confidence to a total of 384 people by random cluster sampling, seeking to make a representative study of the population that is transported in Quito through a poll. The results determined that the population considers congestion as one of the main problems of the city. Meanwhile in research the perception of the population is presented about the various problems that generate traffic in the city. The vehicular increase and the lack of public transport use are analyzed as part of the results and finally the feasibility of using tools such as social networking identified as potencial tools to capture information that allows analyzing alternative solutions to traffic congestion. The study concludes with an analysis of both the main problems and potential solutions to improve traffic and the feasible use of social network Twitter as a tool for decision making for better efficiency of traffic by better use of routes by transportation means as vehicles, achieving research with an initial analysis, but critical to the implementation of potential solutions for decision making in improving traffic congestion in the city.},
author = {{Herrera Herrera}, Nelson Iv{\'{a}}n and {Sanchez Santamaria}, Hector and {Macias Macias}, Miguel and G{\'{o}}mez-Torres, Estevan Ricardo},
booktitle = {2016 Third International Conference on eDemocracy & eGovernment (ICEDEG)},
doi = {10.1109/ICEDEG.2016.7461710},
file = {:C\:/Users/avile/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Herrera Herrera et al. - 2016 - Analysis of the factors generating vehicular traffic in the city of Quito and its relation to the applic.pdf:pdf},
isbn = {978-3-9075-8911-3},
keywords = {Big Data,Big data,Quito,Traffic congestion,Twitter,social data,social networks,traffic,transportation},
mendeley-tags = {Big data,Quito,Traffic congestion,Twitter,social data,social networks,traffic,transportation},
month = {mar},
pages = {133--137},
publisher = {IEEE},
title = {{Analysis of the factors generating vehicular traffic in the city of Quito and its relation to the application of sensorial and social data with big data as a basis for decision making}},
url = {http://ieeexplore.ieee.org/document/7461710/},
year = {2016}
}
@article{ReyesReyes2022600,
abstract = {In the last decade, data collection and analysis have increased considerably in many fields of society. Big Data analysis has begun to play a fundamental role in the advancement of practices and research, as well as in the area of health. In this sense, data mining is a tool that allows you to find useful behavior patterns for decision-making in medicine or clinics, as well as predicting diseases. CVDs are one of the main causes of death in older adults and in the province of Manab{\'{i}} there are no studies reported on the analysis of risk factors for this disease in the elderly population. This research compares the performance of 13 learning algorithms to predict the risk of cardiovascular diseases (CVD) in the population of Manab{\'{i}}, the dataset used is composed of 604 participants, from a study by the National Institute of Statistics and Census (INEC) on health, the well-being of the elderly. The performance of the model was measured by the area under the curve (AUC), obtaining that the model with the best performance is the Random Forest, from which the prediction was made and the value of the variables could be obtained through the Shapley index or more significant risk factors in CVD. In Manabi, these are: if you have shortness of breath, the value of stature_altura if you have taken medication and may or may not have persistent dizziness. {\textcopyright} 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
annote = {cited By 0; Conference of 2nd International Conference on Research and Innovation, CI3 2021 ; Conference Date: 1 September 2021 Through 3 September 2021; Conference Code:281639},
author = {{Reyes Reyes}, F A and {Cruz Felipe}, M D R and Parraga-Alava, J},
doi = {10.1007/978-3-031-11438-0_48},
editor = {{Zambrano Vizuete M. Botto-Tobar M.}, Diaz Cadena A Durakovic B},
file = {:C\:/Users/avile/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Reyes Reyes, Cruz Felipe, Parraga-Alava - 2022 - Prediction of Diseases in the Elderly in Manab{\'{i}} Through Big Data Technologies.pdf:pdf;:C\:/Users/avile/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Reyes Reyes, Cruz Felipe, Parraga-Alava - 2022 - Prediction of Diseases in the Elderly in Manab{\'{i}} Through Big Data Technologies(2).pdf:pdf},
isbn = {9783031114373},
issn = {23673370},
journal = {Lecture Notes in Networks and Systems},
keywords = {Big Data,Data mining,Prediction algorithms,Random Forest},
pages = {600--611},
publisher = {Springer Science and Business Media Deutschland GmbH},
title = {{Prediction of Diseases in the Elderly in Manab{\'{i}} Through Big Data Technologies}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135780169&doi=10.1007%2F978-3-031-11438-0_48&partnerID=40&md5=73ef8267509a3d1b47e24244831bac63},
volume = {511 LNNS},
year = {2022}
}
@inproceedings{Cruz2021,
abstract = {Eradicating poverty in all its forms everywhere remains as the number one Sustainable Development Goal of the 2030 Agenda for Sustainable Development. Developing countries face challenges in measuring the progress of poverty rates at the intra-urban level because they use traditional data collection methods such as censuses that are costly in time and resources. Therefore, local and central governments need ways of producing reliable, accurate, and up-to-date indicators to design effective policies about resource allocation for poverty alleviation programs that prioritize the most vulnerable citizens. For this purpose, we propose to exploit patterns observed in developing countries, where mobile phone usage is pervasive even among the poorest, and the dominant mobile subscription modality is prepaid to purchase airtime credit in advance. Our study analyzes a novel digital source with more than 9M mobile airtime top-up transactions to calculate meaningful indicators of customer economic activity. We aggregate it at the neighborhood spatial resolution to build a regression model to predict the neighborhood socioeconomic status (per capita income). Using a Linear Regression with Regularization L2 (Ridge), we can explain the neighborhood socioeconomic status with a prediction rate of up to 74% for urban neighborhoods of Guayaquil and Quito, Ecuador.},
author = {Cruz, Eduardo and Vaca, Carmen and Villavicencio, Monica},
booktitle = {Proceedings - 2021 IEEE International Conference on Big Data, Big Data 2021},
doi = {10.1109/BigData52589.2021.9671331},
isbn = {9781665439022},
keywords = {computational socioeconomic,data science,per capita income,socioeconomic status,top-up transactions,urban computing},
month = {dec},
pages = {4265--4272},
publisher = {IEEE},
title = {{Estimating urban socioeconomic inequalities through airtime top-up transactions data}},
url = {https://ieeexplore.ieee.org/document/9671331/},
year = {2021}
}
@inproceedings{Mendieta2018,
abstract = {The identification of shrimp organs in biology using histological images is a complex task. Shrimp histological images pose a big challenge due to their texture and similarity between classes of organs. Feature engineering and convolutional neural networks (CNN), as used for image classification, are suitable methods to assist biologists when performing organ detection. This work evaluates the Bag-of-Visual-Words (BOVW) and Pyramid-Bag-of-Words (PBOW) models for image classification using big data techniques and transfer learning for the same classification task by using a pre-Trained CNN. A comparative analysis of these two different techniques is performed, highlighting the characteristics of both approaches on the problem of identification of shrimp organs.},
author = {Mendieta, Milton and Panchana, Fanny and Andrade, Betsy and Bayot, Bonny and Vaca, Carmen and Vintimilla, Boris and Romero, Dennis},
booktitle = {2018 IEEE 3rd Ecuador Technical Chapters Meeting, ETCM 2018},
doi = {10.1109/ETCM.2018.8580315},
isbn = {9781538666579},
keywords = {Aquaculture,CNN,big data,feature extraction,fine-Tuning,histology,organ identification,transfer learning},
pages = {1--6},
title = {{Organ identification on shrimp histological images: A comparative study considering CNN and feature engineering}},
year = {2018}
}
@inproceedings{Ponce-Guevara2018,
abstract = {This work shows the use of Big Data and Data Mining techniques on vegetable crops data from a greenhouse by implementing the first version of a software tool, so called GreenFarm-DM. Such a tool is aimed at analyzing the factors that influence the growth of the crops, and determine a predictive model of soil moisture. Within a greenhouse, the variables that affect crop growth are: relative humidity, soil moisture, ambient temperature, and levels of illumination and CO2. These parameters are essential for photosynthesis, i.e. during processes where plants acquire the most nutrients, and therefore, if performing a good control on these parameters, plants might grow healthier and produce better fruits. The process of analysis of such factors in a data mining context requires designing an analysis system and establishing an objective variable to be predicted by the system. In this case, in order to optimize water resource expenditure, soil moisture has been chosen as the target variable. The proposed analysis system is developed in a user interface implemented in Java and NetBeans IDE 8.2, and consists mainly of two stages. One of them is the classification through algorithm C4.5 (chosen for the first trial), which uses a decision tree based on the data entropy, and allows to visualize the results graphically. The second main stage is the prediction, in which, from the classification results obtained in the previous stage, the target variable is predicted from information of a new set of data. In other words, the interface builds a predictive model to determine the behavior of soil moisture.},
author = {Ponce-Guevara, K. L. and Palacios-Echeverria, J. A. and Maya-Olalla, E. and Dominguez-Limaico, H. M. and Suarez-Zambrano, L. E. and Rosero-Montalvo, P. D. and Peluffo-Ordonez, D. H. and Alvarado-Perez, J. C.},
booktitle = {2017 IEEE 2nd Ecuador Technical Chapters Meeting, ETCM 2017},
doi = {10.1109/ETCM.2017.8247519},
file = {:C\:/Users/avile/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ponce-Guevara et al. - 2017 - GreenFarm-DM A tool for analyzing vegetable crops data from a greenhouse using data mining techniques (Fir.pdf:pdf;:C\:/Users/avile/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ponce-Guevara et al. - 2017 - GreenFarm-DM A tool for analyzing vegetable crops data from a greenhouse using data mining techniques ((2).pdf:pdf;:C\:/Users/avile/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ponce-Guevara et al. - 2017 - GreenFarm-DM A tool for analyzing vegetable crops data from a greenhouse using data mining techniques ((3).pdf:pdf},
isbn = {9781538638941},
keywords = {Big Data,Big data,KDD,Precision agriculture,data analytics,data mining},
mendeley-tags = {Big data,KDD,Precision agriculture,data analytics,data mining},
month = {oct},
pages = {1--6},
publisher = {IEEE},
title = {{GreenFarm-DM: A tool for analyzing vegetable crops data from a greenhouse using data mining techniques (First trial)}},
url = {http://ieeexplore.ieee.org/document/8247519/},
volume = {2017-Janua},
year = {2018}
}
@conference{Plaza2022,
abstract = {The present work aims to characterize the behavior of the Ecuadorian digital consumer in social networks, for which it is proposed to analyze the comments of the tweets published by Ecuadorian companies that offer telecommunications services. The intense use of social networks by the Ecuadorian consumer, and the change in the business model in Ecuadorian businesses due to the health crisis, requires companies to develop digital marketing strategies, advertising or improve products and services they offer to satisfy the needs of the digital consumer. Within the activities, it is proposed to extractthe datathrough the accesstokens of the Twitter API, of the nine processes determined for the treatment of large volumes of data, only six processes that adapt to the requirement of data analysis will beused. In the Jupyter Notebook with the use of Python 3, a word frequency analysis is developed using automatic algorithms. The analyzed results will allow to show positive and negative characteristics of the consumer's interaction in social networksrelatedto the qualityofthe service.},
annote = {cited By 0; Conference of 20th LACCEI International Multi-Conference for Engineering, Education Caribbean Conference for Engineering and Technology, LACCEI 2022 ; Conference Date: 18 July 2022 Through 22 July 2022; Conference Code:182996},
author = {Plaza, Angel M. and Marcillo, Julio and Hidalgo, Jos{\'{e}} and Anchundia, Oscar and Pilacuan, Luis and Parrales, Aldo and Navas, William},
booktitle = {Proceedings of the LACCEI international Multi-conference for Engineering, Education and Technology},
doi = {10.18687/LACCEI2022.1.1.772},
editor = {{Larrondo Petrie M.M. Texier J.}, Pena A Viloria J A S},
isbn = {9786289520705},
issn = {24146390},
keywords = {API,Data mining,JupyterNotebook,Python,Twitter,big data,tokens},
publisher = {Latin American and Caribbean Consortium of Engineering Institutions},
title = {{Text mining for the analysis of digital consumer behavior on Twitter}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140028442&doi=10.18687%2FLACCEI2022.1.1.772&partnerID=40&md5=7a8ad6f834f86e00a70295db8df259c7},
volume = {2022-July},
year = {2022}
}
@inproceedings{10.1145/3148055.3148071,
abstract = {Nowadays, microblog platforms provide a medium to share content and interact with other users. With the large-scale data generated on these platforms, the origin and reasons of users engagement in conversations has attracted the attention of the research community. In this paper, we analyze the factors that might spark conversations in Twitter, for the English and Spanish languages. Using a corpus of 2.7 million tweets, we reconstruct existing conversations, then extract several contextual and content features. Based on the features extracted, we train and evaluate several predictive models to identify tweets that will spark a conversation. Our findings show that conversations are more likely to be initiated by users with high activity level and popularity. For less popular users, the type of content generated is a more important factor. Experimental results shows that the best predictive model is able obtain an average score F1 = 0.80. We made available the dataset scripts and code used in this paper to the research community via Github 1 .},
address = {New York, NY, USA},
author = {Torres, Johnny and Vaca, Carmen and Abad, Cristina L.},
booktitle = {BDCAT 2017 - Proceedings of the 4th IEEE/ACM International Conference on Big Data Computing, Applications and Technologies},
doi = {10.1145/3148055.3148071},
isbn = {9781450355490},
keywords = {Big data,Machine Learning,Social Computing},
pages = {149--156},
publisher = {Association for Computing Machinery},
series = {BDCAT '17},
title = {{What ignites a reply? Characterizing conversations in microblogs}},
url = {https://doi.org/10.1145/3148055.3148071},
year = {2017}
}
@article{Lillo-Castellano2015,
abstract = {The current development of cloud computing is completely changing the paradigm of data knowledge extraction in huge databases. An example of this technology in the cardiac arrhythmia field is the SCOOP platform, a national-level scientific cloud-based big data service for implantable cardioverter defibrillators. In this scenario, we here propose a new methodology for automatic classification of intracardiac electrograms (EGMs) in a cloud computing system, designed for minimal signal preprocessing. A new compression-based similarity measure (CSM) is created for low computational burden, so-called weighted fast compression distance, which provides better performance when compared with other CSMs in the literature. Using simple machine learning techniques, a set of 6848 EGMs extracted from SCOOP platform were classified into seven cardiac arrhythmia classes and one noise class, reaching near to 90% accuracy when previous patient arrhythmia information was available and 63% otherwise, hence overcoming in all cases the classification provided by the majority class. Results show that this methodology can be used as a high-quality service of cloud computing, providing support to physicians for improving the knowledge on patient diagnosis.},
author = {Lillo-Castellano, J. M. and Mora-Jim{\'{e}}nez, I. and Santiago-Mozos, R. and Chavarr{\'{i}}a-Asso, F. and Cano-Gonz{\'{a}}lez, A. and Garc{\'{i}}a-Alberola, A. and Rojo-{\'{A}}lvarez, J. L.},
doi = {10.1109/JBHI.2015.2412175},
issn = {21682208},
journal = {IEEE Journal of Biomedical and Health Informatics},
keywords = {Big data analytics,cardiac arrhythmia classification,implantable defibrillator,intracardiac electrogram,weighted fast compression distance},
month = {jul},
number = {4},
pages = {1253--1263},
pmid = {25823046},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Symmetrical Compression Distance for Arrhythmia Discrimination in Cloud-Based Big-Data Services}},
volume = {19},
year = {2015}
}
@inproceedings{Velasquez2018,
abstract = {This paper states a brief overview of technologies related to Smart Cities and Big Data ecosystems in order to develop and present an architecture proposal for deploying services using the paradigm of Fast Data. The main goal of this architecture, is to present a set of tools and how it could be integrated for providing fast data services focus on Resilient Smart Cities. Finally, proposals for analysis the response times, delays, incidents, and future works are presented.},
author = {Vel{\'{a}}squez, Washington and Munoz-Arcentales, Andres and Salvach{\'{u}}a, Joaquin},
booktitle = {2018 IEEE 8th Annual Computing and Communication Workshop and Conference, CCWC 2018},
doi = {10.1109/CCWC.2018.8301721},
isbn = {9781538646496},
keywords = {Architecture,Big Data,Emergency,Fast Data,IoT,Smart City},
pages = {165--168},
title = {{Fast-data architecture proposal to alert people in emergency}},
volume = {2018-Janua},
year = {2018}
}
@inproceedings{10.1145/3322134.3322154,
abstract = {Big Data has become an important and essential tool for data analysis and decision making due to its fast evolution and rapid penetration in the industry. Therefore, ensuring data security has become a real challenge for Big Data platforms. This work proposes a secure communication system through the implementation of a real scenario consisting of a set of software applications related to the acquisition, transformation and analysis of large amounts of information, also known as stack ELK. More precisely, in our proposal the data are sent encrypted from its source in workstations to their storage with encryption format in Elasticsearch, thus guaranteeing its confidentiality. The results show that the efficiency in the process of generation and delivery of data packets is not affected by the encryption process. The process to secure the messages information requires less than 2 millisecond per data packet, which meets the requirements of realtime monitoring.},
address = {New York, NY, USA},
author = {S{\'{a}}nchez, Marco and Urquiza, Luis},
booktitle = {ACM International Conference Proceeding Series},
doi = {10.1145/3322134.3322154},
isbn = {9781450361866},
keywords = {Big data,Security information,Threats,Vulnerabilities},
pages = {88--92},
publisher = {Association for Computing Machinery},
series = {ICBDE'19},
title = {{Security enhancement through effective encrypted communication using ELK}},
url = {https://doi.org/10.1145/3322134.3322154},
year = {2019}
}
@article{Reyes2019258,
abstract = {An element of great importance for university educational institutions, educators and students is the academic performance of them in the transition of their professional training. The mining of educational data develops models and methods to explore the data collected from the educational learning environments through learning analytics in order to detect patterns that allow predicting variables of interest. The present research describes a predictive model of academic performance using neural network techniques on a set of real data of 300 students of the Systems career of the Central University of Ecuador. This registration was provided by the virtual learning environment https://uvirtual.uce.edu.ec/developed in Moodle and used in said University.},
annote = {cited By 8},
author = {{Salgado Reyes}, Nelson and {Beltr{\'{a}}n Morales}, J{\'{e}}fferson and {Gua{\~{n}}a Moya}, Javier and {Escobar Teran}, Charles and {Nicolalde Rodriguez}, Damian and {Chafla Altamirano}, Gustavo},
issn = {16469895},
journal = {RISTI - Revista Iberica de Sistemas e Tecnologias de Informacao},
keywords = {Academic performance,Big data,Learning analytics,Neural networks},
number = {E17},
pages = {258--266},
publisher = {Associacao Iberica de Sistemas e Tecnologias de Informacao},
title = {{Model to predict academic performance based on neural networks and learning analytics}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061177897&partnerID=40&md5=4eaed2710e019509ffca93c59cea15ad},
year = {2019}
}
@inproceedings{Llerena2021,
abstract = {This work presents a proposal for the progressive use of different methodologies and analytical learning techniques, using two tools available on the Moodle platform. To increase students' retentiveness and to analyze each participant's progress and performance trends are the challenges that Big Data era allows us thanks to data analysis. By closely monitoring student learning and perseverance, it is possible to identify the factors that make them continue with their studies or drop out and thus be able to build predictive models for decision-making. The objective of this work is to show significant changes in the educational processes of student groups that allow teachers to validate, supervise and redirect detailed and specific information through learning analytics with tools available for virtual learning environments, thereby mitigating the risk of loss or desertion.},
address = {Universidad Polit{\'{e}}cnica Salesiana, GiEACI Research Group, Guayaquil, Ecuador},
annote = {Export Date: 23 March 2023},
author = {Llerena, Joe and Alava-Moran, Nohely and Zamora-Galindo, Jonathan},
booktitle = {Proceedings - 2021 2nd International Conference on Information Systems and Software Technologies, ICI2ST 2021},
doi = {10.1109/ICI2ST51859.2021.00022},
editor = {C.I., Jarrin and G., Suntaxi Ona},
isbn = {9780738143613},
keywords = {Educational Innovation,Educational data mining,Higher education,Learning Activities,Learning analytics},
language = {English},
pages = {101--107},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Learning analytics for student academic tracking, a comparison between Analytics Graphs and Edwiser Reports}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111455165&doi=10.1109%2FICI2ST51859.2021.00022&partnerID=40&md5=e776795c20e248e956e5de3485f3c932},
year = {2021}
}
@article{Moya2021,
abstract = {Geospatial big data analytics has received much attention in recent years for the assessment of energy data. Globally, spatial datasets relevant to the energy field are growing rapidly every year. This research has analysed large gridded datasets of outdoor temperature, end-use energy demand, end-use energy density, population and Gros Domestic Product to end with usable inputs for energy models. These measures have been recognised as a means of informing infrastructure investment decisions with a view to reaching sustainable transition of the residential sector. However, existing assessments are currently limited by a lack of data clarifying the spatio-temporal variations within end-use energy demand. This paper presents a novel Geographical Information Systems (GIS)-based methodology that uses existing GIS data to spatially and temporally assess the global energy demands in the residential sector with an emphasis on space heating. Here, we have implemented an Unsupervised Machine Learning (UML)-based approach to assess large raster datasets of 165 countries, covering 99.6% of worldwide energy users. The UML approach defines lower and upper limits (thresholds) for each raster by applying GIS-based clustering techniques. This is done by binning global high-resolution maps into re-classified raster data according to the same characteristics defined by the thresholds to estimate intranational zones with a range of attributes. The spatial attributes arise from the spatial intersection of re-classified layers. In the new zones, the energy demand is estimated, so-called energy demand zones (EDZs), capturing complexity and heterogeneity of the residential sector. EDZs are then used in energy systems modelling to assess a sustainable scenario for the long-term transition of space heating technology and it is compared with a reference scenario. This long-term heating transition is spatially resolved in zones with a range of spatial characteristics to enhance the assessment of decarbonisation pathways for technology deployment in the residential sector so that global climate targets can be more realistic met.},
author = {Moya, Diego and Giarola, Sara and Hawkes, Adam},
doi = {10.1109/BigData52589.2021.9671339},
isbn = {9781665439022},
journal = {Proceedings - 2021 IEEE International Conference on Big Data, Big Data 2021},
keywords = {Heat demand,integrated assessment,spatial big data analytics,spatial datasets,spatiotemporal},
pages = {4035--4046},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Geospatial Big Data analytics to model the long-term sustainable transition of residential heating worldwide}},
year = {2021}
}
@inproceedings{Cepeda2022,
abstract = {After a perturbation, the generators shift their operating condition in search of new equilibrium states (steady states), overpassing a dynamic.state (which should be transitory), characterized by power and frequency oscillations. Oscillations are marked by the so-called oscillation modes that are determined by three fundamental parameters: Amplitude (MW), Frequency (Hz), and Damping Ratio (%). These oscillatory modes can be estimated in real-time using modal estimation algorithms applied to signals recorded by Phasor Measurement Units (PMUs) within a Wide Area Monitoring System (WAMS). These estimations are made each time a new sample arrives, so they do not provide predictions of the future status of oscillatory stability. However, an aspect of relevance in the operation of electric power systems is the need for the operator to have "early warnings"that allow him to make decisions sufficiently in advance to carry out control actions. In this sense, it is necessary to have short-term prediction mechanisms (a few seconds in the future) of the modal analysis results, which allow the operator to anticipate the evolution of the operating state to predictively evaluate the oscillatory stability of the system. In this sense, a Big Data platform to analyze the streaming data that comes from WAMS, being capable of analyzing the data from the modal estimation and performing a predictive evaluation, automatically, of the oscillatory stability status, is proposed. Therefore, this work presents the platform's key implementation aspects, which are based on Data Management Technologies (Cassandra), together with a Data Analytics software (Python), in which a time series regressor is trained based on recurrent neural networks (RNN). This methodology is applied to the Ecuadorian Electric Power System, taking advantage of its WAMS platform WAProtector.},
author = {Cepeda, Jaime and Gomez, Ignacio and Calero, Fabian and Vaca, Angel},
booktitle = {2022 International Conference on Smart Grid Synchronized Measurements and Analytics, SGSMA 2022 - Proceedings},
doi = {10.1109/SGSMA51733.2022.9806014},
isbn = {9789531842822},
keywords = {Modal Estimation,Oscillatory Stability,Phasor Measurement Unit,Recurrent Neural Networks,Wide Area Monitoring System},
month = {may},
pages = {1--6},
publisher = {IEEE},
title = {{Big Data Platform for Real-Time Oscillatory Stability Predictive Assessment Using Recurrent Neural Networks and WAProtector's Records}},
url = {https://ieeexplore.ieee.org/document/9806014/},
year = {2022}
}
@inproceedings{Bonilla2018,
abstract = {As the number of IoT devices continues to increase, so does the number of challenges we need to face. Security is a big concern since the number of attacks to IoT devices keeps rising. We show that currently available Security metrics do not correctly apply to IoT devices, and propose an appropriate metric. As a proof-of-concept, we apply our metric to three IoT devices and show that it reacts to the presence of vulnerabilities as well as actual exploits.},
author = {Bonilla, Rafael I. and Crow, Juan J. and Basantes, Luigi S. and Cruz, Luis G.},
booktitle = {2017 IEEE 15th Intl Conf on Dependable, Autonomic and Secure Computing, 15th Intl Conf on Pervasive Intelligence and Computing, 3rd Intl Conf on Big Data Intelligence and Computing and Cyber Science and Technology Congress(DASC/PiCom/DataCom/CyberSciTech)},
doi = {10.1109/DASC-PICom-DataCom-CyberSciTec.2017.123},
isbn = {978-1-5386-1956-8},
keywords = {Internet-of-things,Metric,Security},
month = {nov},
pages = {704--709},
publisher = {IEEE},
title = {{A Metric for Measuring IoT Devices Security Levels}},
url = {http://ieeexplore.ieee.org/document/8328467/},
volume = {2018-Janua},
year = {2017}
}
@inproceedings{San-Lucas2016,
abstract = {This paper presents StorageSim, a multi-tier storage system simulator. StorageSim is a process-based discrete-event simulator developed using the SimPy simulation framework. It simulates the operation of a multi-tiered storage system; for example, a system that stores super 'hot' files in non-volatile RAM, less 'hot' files in solid state drives (SSDs) and 'warm' and 'cold' files in hard disk drives (HDDs). StorageSim comes with three data-placement policies, and can be extended to support other policies. It can replay publicly available storage traces from the Storage Networking Industry Association (SNIA) and other public sources, and can be used to evaluate data-placement policies prior to implementing them on a real system. By abstracting away many complex details, StorageSim provides a fast simulation framework that can be used to simulate large scale storage systems. Experimental results show that StorageSim is useful, can reproduce prior results from real deployments, and is fast enough to handle Big Data workloads in a timely manner.},
author = {San-Lucas, Cesar and Abad, Cristina L.},
booktitle = {2016 IEEE Ecuador Technical Chapters Meeting, ETCM 2016},
doi = {10.1109/ETCM.2016.7750836},
isbn = {9781509016297},
keywords = {Big data,Hard disks,Industries,Load modeling,Random access memory,Solids,System analysis and design},
pages = {1--5},
title = {{Towards a fast multi-tier storage system simulator}},
year = {2016}
}
@inproceedings{Silva2022,
abstract = {The implementation of new technologies provides greater quality control in civil works, both structural and mechanical. In developed countries such as China and Australia, the virtual reality industry and data management have developed hand in hand with Industry 4.0, which means that the use of quality parameters in a process before, during and after making decisions, becomes a standard every day more accurate, such is the case of applications focused on IoT (Internet of Things), where the communication of devices and mechanical means, allows better control, increasing performance, reducing risks and streamlining production lines. In this sense, a virtual tool associated with welding parameters facilitates the operator's control in the processes of identifying manufacturing measures before, during and after each operation, allowing him to train and improve based on his data, with data that can be compared and evaluated, giving him a pattern of constant improvement, Ecuador seeks to adapt to the dizzying changes of the technological era and solve several drawbacks within the construction area, Among them, the complexity in the field of welding and the high costs involved in the acquisition of equipment, training and experts, being in most cases obsolete, for this reason the focus of this project is to focus on improving the SWAG and MIG processes, connecting data operations through a server hosted in the cloud and presenting it through an augmented reality tool that allows the user to train and measure their knowledge.},
author = {Silva, Jessica and Lara, Mario and Bayas, Myriam and Mopocita, Luis and Jerez, Daniel and Herrera, Gabriela},
booktitle = {2022 5th International Conference on Computing and Big Data (ICCBD)},
doi = {10.1109/ICCBD56965.2022.10080320},
isbn = {978-1-6654-5716-3},
keywords = {Cloud Computing,Internet of things,MIG augmented reality,SWAG,Software,welding parameters},
month = {dec},
pages = {29--33},
publisher = {IEEE},
title = {{Augmented Reality Tool Based in the Cloud to Improve the Quality of SMAW and MIG Processes Through Data Comparison}},
url = {https://ieeexplore.ieee.org/document/10080320/},
year = {2022}
}
@article{Villegas-Ch2019,
abstract = {Currently, the integration of technologies such as the Internet of Things and big data seeks to cover the needs of an increasingly demanding society that consumes more resources. The massification of these technologies fosters the transformation of cities into smart cities. Smart cities improve the comfort of people in areas such as security, mobility, energy consumption and so forth. However, this transformation requires a high investment in both socioeconomic and technical resources. To make the most of the resources, it is important to make prototypes capable of simulating urban environments and for the results to set the standard for implementation in real environments. The search for an environment that represents the socioeconomic organization of a city led us to consider universities as a perfect environment for small-scale testing. The proposal integrates these technologies in a traditional university campus, mainly through the acquisition of data through the Internet of Things, the centralization of data in proprietary infrastructure and the use of big data for the management and analysis of data. The mechanisms of distributed and multilevel analysis proposed here could be a powerful starting point to find a reliable and efficient solution for the implementation of an intelligent environment based on sustainability.},
annote = {Campus inteligente},
author = {Villegas-Ch, William and Palacios-Pacheco, X and Luj{\'{a}}n-Mora, Sergio},
doi = {10.3390/su11102857},
file = {:C\:/Users/avile/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Villegas-Ch, Palacios-Pacheco, Luj{\'{a}}n-Mora - 2019 - Application of a Smart City Model to a Traditional University Campus with a Big Data.pdf:pdf},
issn = {20711050},
journal = {Sustainability (Switzerland)},
keywords = {Big data,Hadoop,IoT,Smart campus,Smart cities,Sustainability},
month = {may},
number = {10},
pages = {2857},
publisher = {Multidisciplinary Digital Publishing Institute},
title = {{Application of a smart city model to a traditional university campus with a big data architecture: A sustainable smart campus}},
url = {https://www.mdpi.com/2071-1050/11/10/2857/htm https://www.mdpi.com/2071-1050/11/10/2857},
volume = {11},
year = {2019}
}
@article{Castillo-López2020239,
abstract = {Large scale natural disasters involve budgetary problems for governments even when local and foreign humanitarian aid is available. Prioritizing investment requires near real time information about the impact of the hazard in different locations. However, such information is not available through sensors or other devices specially in developing countries that do not have such infrastructure. A rich source of information is the data resulting from mobile phones activity that citizens in affected areas start using as soon as it becomes available post-disaster. In this work, we exploit such source of information to conduct different analyses in order to infer the affected zones in the Ecuadorian province of Manab{\'{i}}, after the 2016 earthquake, with epicenter in the same province. We propose a series of features to characterize a geographic area, as granular as a canton, after a natural disaster and label its level of damage using mobile phone data. Our methods result in a classifier based on the K-Nearest Neighbors algorithm to detect affected zones with a 75% of accuracy. We compared our results with official data published two months after the disaster.},
annote = {cited By 1; Conference of 6th International Conference on Information Management and Big Data, SIMBig 2019 ; Conference Date: 21 August 2019 Through 23 August 2019; Conference Code:239409},
author = {Castillo-L{\'{o}}pez, Galo and Guaranda, Mar{\'{i}}a Bel{\'{e}}n and Layedra, Fabricio and Vaca, Carmen},
doi = {10.1007/978-3-030-46140-9_23},
editor = {{Lossio-Ventura J.A. Condori-Fernandez N.}, Valverde-Rebaza J C},
isbn = {9783030461393},
issn = {18650937},
journal = {Communications in Computer and Information Science},
keywords = {Disaster management,Mobile phones activity,Spatio-temporal analysis},
pages = {239--251},
publisher = {Springer},
title = {{A Place to Go: Locating Damaged Regions After Natural Disasters Through Mobile Phone Data}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084801612&doi=10.1007%2F978-3-030-46140-9_23&partnerID=40&md5=59e236146ba3ec2e8f3c212d0c36f676},
volume = {1070 CCIS},
year = {2020}
}
@article{Orellana2021205,
abstract = {Lately, there is a concern about to air pollution, which leads to environmental specialists discovering relevant causes of this phenomenon. Several factors determine the level of pollution, but it is necessary to find behavior patterns between air pollution and meteorological variables. The relations between these variables in distinct hours a day could give clues to discover essential patterns in their relationships. This study revealed relations among five air pollution variables and nine meteorological variables collected for one month in the city Cuenca-Ecuador. The method used considerer an evaluation of the essential time associations using time rolling windows and correlations. The results were revelated using visualization frames for dimensions such as time, correlation rate, and component relation, highlighting 57 strong correlations from 91 pairs of variables, the best positive correlation is between Ozone and Radiation UVA. The best negative correlation is Ozone and Dew Point, both throughout the day.},
annote = {cited By 1; Conference of Future of Information and Communication Conference, FICC 2021 ; Conference Date: 29 April 2021 Through 30 April 2021; Conference Code:257959},
author = {Orellana, Marcos and Lima, Juan Fernando and Cedillo, Priscila},
doi = {10.1007/978-3-030-73103-8_13},
editor = {K., Arai},
isbn = {9783030731021},
issn = {21945365},
journal = {Advances in Intelligent Systems and Computing},
keywords = {Air pollutant,Big data,Correlation,Data Mining,Knowledge,Rolling correlations},
pages = {205--215},
publisher = {Springer Science and Business Media Deutschland GmbH},
title = {{Discovering Patterns of Time Association Among Air Pollution and Meteorological Variables}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105946376&doi=10.1007%2F978-3-030-73103-8_13&partnerID=40&md5=e4afa85daf6b1f960ddedc6f5b4d9ca7},
volume = {1364 AISC},
year = {2021}
}
@article{Carrión2020490,
abstract = {The research focuses on knowing what the current reality is in relation to the use of large databases and their visualization within the media of 23 Ibero-American countries. In this context, 100 news stories are analyzed with big data content in each country, including a US medium. To conclude with the research objectives, the use of qualitative and quantitative methodologies applied in content sheets was determined: data journalism to learn about big data; in addition to interviews with experts in the field. Among the main results of the investigation, it was found that media such as La Naci{\'{o}}n (Argentina), El Deber (Bolivia), La Naci{\'{o}}n (Costa Rica), El Comercio (Ecuador), El Pa{\'{i}}s (Spain), The New York Times (New York), handle large amounts of data and distribute the information through new online narratives with an interdisciplinary synergy between: journalists, web developers and programmers, infographers, sociologists, statisticians, editors and editors. In these cases and using a strategic business model, the quality content allows loyalty to the prosumer.},
annote = {cited By 0},
author = {{Paucar Carri{\'{o}}n}, Katty Yadira and Coronel-Salas, Gabriela},
issn = {16469895},
journal = {RISTI - Revista Iberica de Sistemas e Tecnologias de Informacao},
keywords = {Big data,Data journalism,Ibero-American,Social media},
number = {E35},
pages = {490--502},
publisher = {Associacao Iberica de Sistemas e Tecnologias de Informacao},
title = {{Big data in the ibero-american mass media}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094595999&partnerID=40&md5=5270f821a2cdb7b312f84cd0549264eb},
volume = {2020},
year = {2020}
}
@article{Tenesaca-Luna2019314,
abstract = {The present work uses Hadoop as the core processing in the Big Data environment. There are several open sources tools from the Hadoop ecosystem that facilitate the processing of enormous volumes of data. In this paper, we have worked with Apache Flume and Apache Hive tools for the study case of the 2017 presidential elections in Ecuador. The analysis of data generated from Twitter social network focuses mainly in the first round of balloting of Ecuador's 2017 presidential election. These generated data have been obtained, stored, processed and analyzed to comply with the characteristics of the information that is considered Big Data. The selected tools have been evaluated in their architecture, installation, and use. Finally, the data have been evaluated under certain quality criteria or dimensions.},
annote = {cited By 1; Conference of 6th Conference on Information Technologies and Communication of Ecuador, TIC-EC 2018 ; Conference Date: 21 November 2018 Through 23 November 2018; Conference Code:219929},
author = {{Tenesaca Luna}, Gladys Alicia and Imba, Diego and Mora-Arciniegas, Mar{\'{i}}a Bel{\'{e}}n and Segarra-Faggioni, Ver{\'{o}}nica and Ram{\'{i}}rez-Coronel, Ramiro Leonardo},
doi = {10.1007/978-3-030-02828-2_23},
editor = {{Botto-Tobar M. Barba-Maggi L.}, Villacres-Cevallos P Uvidia-Fassler M I Gonzalez-Huerta J S Gomez O},
file = {:C\:/Users/avile/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Tenesaca-Luna et al. - 2019 - Use of Apache Flume in the Big Data Environment for Processing and Evaluation of the Data Quality of the T.pdf:pdf;:C\:/Users/avile/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Tenesaca-Luna et al. - 2019 - Use of Apache Flume in the Big Data Environment for Processing and Evaluation of the Data Quality of th(2).pdf:pdf},
isbn = {9783030028275},
issn = {21945357},
journal = {Advances in Intelligent Systems and Computing},
keywords = {Apache Flume,Big Data,Twitter},
pages = {314--326},
publisher = {Springer Verlag},
title = {{Use of Apache Flume in the Big Data Environment for Processing and Evaluation of the Data Quality of the Twitter Social Network}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055654544&doi=10.1007%2F978-3-030-02828-2_23&partnerID=40&md5=117cf635b1d3acdc93c4fb6da97abf92},
volume = {884},
year = {2019}
}
@conference{Andrea20181,
abstract = {Deep Learning is playing an important role in big data processing for more accurate modeling of common productive processes. It is being widely used in artificial vision applications and specifically in pattern recognition. The versatility of deep learning has positioned it as a fit tool used in many fields of application, among which is precision agriculture. This paper presents the development of an algorithm capable of image segmentation and classification. Segmentation is intended to separate the target plant from the original image, while classification is meant to identify what images belong to the two defined classes. It applies a convolutional neural network (CNN) to discriminate maize plants from weeds in real time, at early crop development stages. It was applied to maize crop because it is a common staple crop in the Ecuadorian Highlands. The convolutional neural network has been trained with a dataset generated in the segmentation stage. The performance of the network was analyzed with LeNET, AlexNet, cNET and sNET network architectures. The network architecture that presented the best training results was cNET based on its performance in terms of accuracy and processing time. The minimum working filter number for this network architecture was 16. The best performing algorithms and processors have a significant potential for autonomous weed and crop classification systems in a real-time application.},
annote = {cited By 36; Conference of 2nd IEEE Ecuador Technical Chapters Meeting, ETCM 2017 ; Conference Date: 16 October 2017 Through 20 October 2017; Conference Code:134105},
author = {{Cordova Cruzatty}, Andrea and Barreno, Mauricio Daniel and {Jacome Barrionuevo}, Jose Misael},
booktitle = {2017 IEEE 2nd Ecuador Technical Chapters Meeting, ETCM 2017},
doi = {10.1109/ETCM.2017.8247469},
isbn = {9781538638941},
keywords = {Artificial neural networks,Classification algorithms,Image sampling,Image segmentation,Machine learning,Supervised learning},
pages = {1--6},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Precise weed and maize classification through convolutional neuronal networks}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045750501&doi=10.1109%2FETCM.2017.8247469&partnerID=40&md5=cb9b8d5c7016c7d7f5d0da43c1eeb2cf},
volume = {2017-Janua},
year = {2018}
}
@inproceedings{Kuffo2019,
abstract = {Customers nowadays are one online post away from their stores, specially when it comes to post-shopping experiences. This translates to large amounts of text messages to evaluate and process for big brands that aim to maintain a good quality of service as well as a digital channel of communication for their customers. Automating the understanding of this text data poses questions such as how large the corpus should be and which are the best algorithms to discriminate whether a social media post is related or not to customer experience (CX). In order to help answering these questions, first, we get hold of posts from three different platforms: Foursquare (77K) , Twitter (153K) and Facebook (2.2M). Such posts are directed to brands ranked in the ForeSee CX Index and the Forrester CX Index rankings. Second, we build a binary classifier using different algorithms to identify customer experience posts on a social platform. The accuracy of the best performing setting is 86.4% for Facebook and 91.2% for Twitter. Third, we explore the effect of increasing the number of training samples, and how a plateau is reached after 5K posts. Finally, we conduct experiments using different combinations of n-grams as features for the text mining process. As a result we observe that uni-grams and bi-grams are the best combination when we need to choose features for a classifier discriminating customer experience social media posts on Twitter and a combination of up to four-grams on Facebook.},
author = {Kuffo, Leonardo and Vaca, Carmen and Izquierdo, Edgar and Bustamante, Juan Carlos},
booktitle = {2018 IEEE International Conference on Big Data (Big Data)},
doi = {10.1109/BigData.2018.8622556},
isbn = {978-1-5386-5035-6},
keywords = {Customer Experience,Data Science,Machine Learning,Social Media,Text categorization},
month = {dec},
pages = {4086--4094},
publisher = {IEEE},
title = {{Know your customer: Detection of Customer Experience (CX) in Social Platforms using Text Categorization}},
url = {https://ieeexplore.ieee.org/document/8622556/},
year = {2018}
}
@inproceedings{Urena-Torres2017,
abstract = {This work presents an analysis of some terms related to Big Data, Hadoop, and their architecture; in addition, it presents the results of the analysis of undergraduate enrollment information of the distance system of Universidad Tecnica Particular de Loja (UTPL), this information is extracted from academic system by using Hadoop framework as a big data processing platform; for that, a big data infrastructure has been designing and tested which is based on Hortonworks and Power View tools in order to present reports that helps managers to have metrics in order to improve their decision making. For this, a thorough search of information by using Hadoop framework, in which a synthesis of the different important terms was made, it reaches to determine different areas of application; in addition it presents a big data case study by of undergraduate enrollment information from academic system of UTPL by using the Hadoop framework. Consequently, it is concluded that Hadoop Framework helps us to process of big data sets, because it has Hadoop Distributed File System which provides an increased performance for data, and MapReduce process the data in parallel with the integration of Hortonworks and Power View tools which allow to analyze big data and to present reports in maps in order to analyze UTPL students enrollment.},
annote = {From Duplicate 1 (Analysis and processing of academic data from a higher institution with tools for big data - Urena-Torres, Juan-Pablo; Tenesaca-Luna, Gladys-Alicia; Arciniegas, Maria Belen Mora)

cited By 1; Conference of 12th Iberian Conference on Information Systems and Technologies, CISTI 2017 ; Conference Date: 21 June 2017 Through 24 June 2017; Conference Code:129105

From Duplicate 2 (Analysis and processing of academic data from a higher institution with tools for big data - Urena-Torres, Juan-Pablo Pablo; Tenesaca-Luna, Gladys-Alicia Alicia; Arciniegas, Maria Belen Mora)

From Duplicate 1 (Analysis and processing of academic data from a higher institution with tools for big data - Urena-Torres, Juan-Pablo; Tenesaca-Luna, Gladys-Alicia; Arciniegas, Maria Belen Mora)

cited By 1; Conference of 12th Iberian Conference on Information Systems and Technologies, CISTI 2017 ; Conference Date: 21 June 2017 Through 24 June 2017; Conference Code:129105},
author = {Urena-Torres, Juan-Pablo and {Tenesaca Luna}, Gladys Alicia and Arciniegas, Maria Belen Mora},
booktitle = {2017 12th Iberian Conference on Information Systems and Technologies (CISTI)},
doi = {10.23919/CISTI.2017.7975822},
editor = {{Reis L.P. Rocha A.}, Alturas B Costa C Cota M P},
file = {:C\:/Users/avile/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Urena-Torres, Tenesaca-Luna, Mora-Arciniegas - 2017 - Analysis and processing of academic data from a higher institution with tools for.pdf:pdf},
isbn = {9789899843479},
issn = {21660727},
keywords = {Academic system,Big Data,Big data,Data handling,Data infrastructure,Data mining,Decision making,Education,File organization,Hadoop,Hadoop distributed file systems,Hadoop frameworks,Hive,Hortonworks,Information systems,Network function virtualization,Power View,Search engines},
month = {jun},
pages = {1--4},
publisher = {IEEE},
title = {{Analysis and processing of academic data from a higher institution with tools for big data}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027222059&doi=10.23919%2FCISTI.2017.7975822&partnerID=40&md5=56ca3a75474664cbdca6fdc990e457c6 http://ieeexplore.ieee.org/document/7975822/},
year = {2017}
}
@conference{Andrade20193383,
abstract = {Natural disasters have proven that governments, even in developed countries, have difficulties to get up-to-date data about not only affected people but also the location and intensity of infrastructure damage when a country is shook by the nature. Therefore, knowing how mobility patterns are changing, in the post disaster time-frame, is crucial in order to settle rescue centers and send help to the most affected areas. In this scenario, we analyze the relations between human mobility patterns and the effects of an earthquake that shook Ecuador on April 16th, 2016. We do so using more than 11 millions of aggregated call detail records provided by Telefonica. We propose a metric named Reach Score to build timeseries as a way to characterize the residents geographic reach according to their mobile activity. Next, we define the metric Reach Score change, RiSC to capture differences in mobility among two given dates. Our results show that these two metrics calculated on data from the day before and the day after the disaster reflect both the overall change in mobility at the province level and the intensity of infrastructure damage at canton level. In fact, we obtain a Pearson correlation coefficient of r = -0.819 between the metric RiSC and the infrastructure damage score taken from official data. {\textcopyright} 2018 IEEE.},
annote = {cited By 7; Conference of 2018 IEEE International Conference on Big Data, Big Data 2018 ; Conference Date: 10 December 2018 Through 13 December 2018; Conference Code:144531},
author = {Andrade, Xavier and Layedra, Fabricio and Vaca, Carmen and Cruz, Eduardo},
booktitle = {2018 IEEE International Conference on Big Data (Big Data)},
doi = {10.1109/BigData.2018.8622374},
editor = {{Song Y. Liu B.}, Lee K Abe N Pu C Qiao M Ahmed N Kossmann D Saltz J Tang J He J Liu H Hu X},
file = {:C\:/Users/avile/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Andrade et al. - 2019 - RiSC Quantifying change after natural disasters to estimate infrastructure damage with mobile phone data.pdf:pdf;:C\:/Users/avile/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Andrade et al. - 2019 - RiSC Quantifying change after natural disasters to estimate infrastructure damage with mobile phone data(2).pdf:pdf},
isbn = {978-1-5386-5035-6},
keywords = {Big data,Call detail records,Correlation methods,Developed c,Disasters,aggregated CDRs},
month = {dec},
pages = {3383--3391},
publisher = {IEEE},
title = {{RiSC: Quantifying change after natural disasters to estimate infrastructure damage with mobile phone data}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062604509&doi=10.1109%2FBigData.2018.8622374&partnerID=40&md5=3996bf2e1fc90cc1c669848213a2efe7 https://ieeexplore.ieee.org/document/8622374/},
year = {2018}
}
@article{Molina-Granja2023891,
abstract = {Data science aims to describe methods, techniques, data analytics strategies, mathematical, statistical, and computational modeling for engineering and data science, for timely decision-making, and also in the interaction of these areas and the tools that result from it, through the transversal and applied nature of the program, with the ability to address and solve complex problems in an innovative way. Planning, designing and executing data science projects, aligning them with accepted regulations, good practices, and IT governance, this study aims to demonstrate the relevance of the creation of the Data Science engineering career, specifically in Ecuador, obtaining as a result, a favorable response to relevance, with high scores of interest and acceptability in studies and relevance in the area of data sciences, including the study also reflects a global trend in this area.},
annote = {cited By 0; Conference of 6th International Conference on Inventive Communication and Computational Technologies, ICICCT 2022 ; Conference Date: 12 May 2022 Through 13 May 2022; Conference Code:286309},
author = {Molina-Granja, Fernando and Barba, Lida and Molina, Lorena and Bustamante, Wayner and Ashok, B. and Swaminathan, J. N.},
doi = {10.1007/978-981-19-4960-9_67},
editor = {{Ranganathan G. Fernando X.}, Rocha A},
isbn = {9789811949593},
issn = {23673389},
journal = {Lecture Notes in Networks and Systems},
keywords = {Big data,Data science,Data science engineering,Relevance study},
pages = {891--903},
publisher = {Springer Science and Business Media Deutschland GmbH},
title = {{Study of Relevance of the Engineering Career in Data Science}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142745374&doi=10.1007%2F978-981-19-4960-9_67&partnerID=40&md5=5de7ffc8390a30c12d5ef700e9213cae},
volume = {383},
year = {2023}
}
@inproceedings{Guaman2019,
abstract = {This paper presents a process of obtaining a forecast of the demand for electricity in the Empresa El{\'{e}}ctrica Ambato Regional Centro Norte S.A. (EEASA) using Big Data criteria. A computational model in programming language PYTHON 3.7 was developed. Implementing an electric load projection application in which machine learning algorithms are integrated, such as Autoregressive Integrated Moving Average, Linear Regression, Support Vector Machine and the Multilayer Perceptron. Additionally, different study cases were considered as the most frequent scenarios for the generation of electric load projections such as: a week with holidays, a week with scheduled and unscheduled incidence, a week in dry season and week in rainy season, which allowed test each implemented algorithm, evaluate its results and compare them with each other by calculating the indicators of the percentage of average absolute error (PEMA) and the accuracy of the projection (EP).},
author = {Guaman, Alexis and Ramirez, Juan and Mayorga, Bryan and Aviles, Fausto and Gallardo, Carlos},
booktitle = {Proceedings - 2019 International Conference on Information Systems and Computer Science, INCISCOS 2019},
doi = {10.1109/INCISCOS49368.2019.00013},
file = {:C\:/Users/avile/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Guaman et al. - 2019 - Short-Term Load Forecasting in the Distribution System of the Electric Company of Ambato (EEASA) Based on Big Dat.pdf:pdf},
isbn = {9781728155814},
keywords = {Big Data,Empresa El{\'{e}}ctrica Ambato,machine learning,modelo autorregresivo integrado de media m{\'{o}}vil,m{\'{a}}quina de vector soporte,perceptr{\'{o}}n multicapa,proyecci{\'{o}}n de carga el{\'{e}}ctrica,regresi{\'{o}}n lineal},
pages = {23--30},
title = {{Short-Term Load Forecasting in the Distribution System of the Electric Company of Ambato (EEASA) Based on Big Data Criteria}},
year = {2019}
}
@article{Villegas-Ch2018138,
abstract = {This paper presents an analysis of new concepts such as big data, smart data and a data lake. It is to sought integrate learning management systems with these platforms and contribute to education by making it personalised and of quality. For this study, the data and needs of a university in Ecuador have been considered. This university has set its goals to the discovery of patterns, using data mining techniques applied to cubes generated in a data warehouse. However, the institution wants to integrate all the systems and sensors that contribute to the educational development of the student. Integrating more systems into the data warehouse has compromised the veracity of the data and the processing capabilities have been surpassed by the volume of data. The paper proposes the use of one of the platforms analysed and its tools to generate knowledge and to help the students to learn.},
annote = {cited By 22; Conference of International Conference on Information Technology and Systems, ICITS18 ; Conference Date: 11 January 2017 Through 13 January 2017; Conference Code:209489},
author = {Villegas-Ch, William and Luj{\'{a}}n-Mora, Sergio and Buena{\~{n}}o-Fern{\'{a}}ndez, Diego and Palacios-Pacheco, X},
doi = {10.1007/978-3-319-73450-7_14},
editor = {{Rocha A.}, Guarda T},
isbn = {9783319734491},
issn = {21945357},
journal = {Advances in Intelligent Systems and Computing},
keywords = {Analysis of data,Big data,Data lake,Data mining,Data warehouse,Smart data},
pages = {138--147},
publisher = {Springer Verlag},
title = {{Big data, the next step in the evolution of educational data analysis}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041066609&doi=10.1007%2F978-3-319-73450-7_14&partnerID=40&md5=67a3212c52caecc6055b5d90cf1e9619},
volume = {721},
year = {2018}
}
@inproceedings{Moscoso-Zea2016,
abstract = {Business intelligence (BI) builds upon a set of tools and applications that enable the analysis of vast amounts of information (Big Data). Educational institutions handle large volumes of Big Data every year. There is a strong need for the use of BI in these institutions to improve their processes and support decision making. The core technology in a BI project is a datawarehouse (DW). This paper describes the design considerations for the implementation of the DW in an educational scenario. The DW will be used in a knowledge discovery process to handle the information for the analysis of key performance indicators using educational data mining (EDM) techniques. The DW along with an enterprise architecture (EA) repository are the key technological assets of a knowledge management framework (KMF). This framework was designed to put order in the creation, capture, transfer and digitalization of knowledge. This guide and the framework are two of the outcomes of a research project in a private university. Furthermore, a case study suggests how to choose the best methodology in higher institutions. In the case study the steps for the DW design are presented. This study can be useful for academics and practitioners that plan to design a DW to analyze information using EDM techniques.},
author = {Moscoso-Zea, Oswaldo and Andres-Sampedro and Luj{\'{a}}n-Mora, Sergio},
booktitle = {2016 15th International Conference on Information Technology Based Higher Education and Training, ITHET 2016},
doi = {10.1109/ITHET.2016.7760754},
isbn = {9781509007783},
keywords = {Business intelligence,Datawarehouse,ETL,Educational data mining,Knowledge management},
pages = {1--6},
title = {{Datawarehouse design for educational data mining}},
year = {2016}
}
@article{Iván-Herrera-Herrera2018363,
abstract = {The purpose of this study is to present an analysis of the use and integration of technological tools that help decision making in situations of vehicular congestion. The city of Quito-Ecuador is considered as a case study for the done work. The research is presented according to the development of an application, using Big Data tools (Apache Flume, Apache Hadoop, Apache Pig), favoring the processing of a lot of information that is required to collect, store and process. One of the innovative aspects of the application is the use of Twitter social network as source of origin. For this, it used its application programming interface (API), which allows to take data from this social network and identify probable points of congestion. This study presents results of tests carried out with the application, in a period of 9 months.},
annote = {cited By 2},
author = {{Herrera Herrera}, Nelson Iv{\'{a}}n and Luj{\'{a}}n-Mora, Sergio and G{\'{o}}mez-Torres, Estevan Ricardo},
doi = {10.15446/dyna.v85n205.67745},
issn = {00127353},
journal = {DYNA (Colombia)},
keywords = {Application,Big data,Congestion,Quito,Traffic,Twitter},
number = {205},
pages = {363--370},
publisher = {Universidad Nacional de Colombia},
title = {{Integration of tools for decision making in vehicular congestion}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060973816&doi=10.15446%2Fdyna.v85n205.67745&partnerID=40&md5=cfda9a8d18e99a95968afcefe5c98b9e},
volume = {85},
year = {2018}
}
@inproceedings{Saquicela2017,
abstract = {Currently, we are witnessing an exponential growth in the amount of data being generated and captured at multiple locations. This trend will continue over the next years. Hence, we have envisioned a scenario in which many objects will be referencing to or generating location information. Thus, the need for appropriately managing geospatial data is evident. In this paper, we present our vision for an integral Geo Linked Data platform; pointing out the current limitations and challenges in the GeoRDFization, Storage, Query Federation, and Visualization of data with an inherent spatial context.},
author = {Saquicela, Victor and Vilches-Blazquez, Luis M. and Tello, Andres},
booktitle = {2017 IEEE International Conference on Big Data (Big Data)},
doi = {10.1109/BigData.2017.8258335},
isbn = {978-1-5386-2715-0},
keywords = {GeoRDFization,GeoSPARQL,federated queries},
month = {dec},
pages = {3471--3475},
publisher = {IEEE},
title = {{Challenges and trends about smart big geospatial data: A position paper}},
url = {http://ieeexplore.ieee.org/document/8258335/},
volume = {2018-Janua},
year = {2017}
}
@article{Moscoso-Zea2019,
abstract = {Advances in science and technology, the Internet of Things, and the proliferation of mobile apps are critical factors to the current increase in the amount, structure, and size of information that organizations have to store, process, and analyze. Traditional data storages present technical deficiencies when handling huge volumes of data and are not adequate for process modeling and business intelligence; to cope with these deficiencies, new methods and technologies have been developed under the umbrella of big data. However, there is still the need in higher education institutions (HEIs) of a technological tool that can be used for big data processing and knowledge management (KM). To overcome this issue, it is essential to develop an information infrastructure that allows the capturing of knowledge and facilitates experimentation by having cleaned and consistent data. Thus, this paper presents a hybrid information infrastructure for business intelligence and analytics (BIA) and KM based on an educational data warehouse (EDW) and an enterprise architecture (EA) repository that allows the digitization of knowledge and empowers the visualization and the analysis of dissimilar organizational components as people, processes, and technology. The proposed infrastructure was created based on research and will serve to run different experiments to analyze educational data and academic processes and for the creation of explicit knowledge using different algorithms and methods of educational data mining, learning analytics, online analytical processing (OLAP), and EA analytics.},
address = {Facultad de Ciencias de la Ingenieria e Industrias, Universidad Tecnologica Equinoccial, Quito, 170509, Ecuador},
annote = {Cited By :24

Export Date: 23 March 2023

Correspondence Address: Moscoso-Zea, O.; Facultad de Ciencias de la Ingenieria e Industrias, Ecuador; email: omoscoso@ute.edu.ec},
author = {Moscoso-Zea, Oswaldo and Castro, Jorge and Paredes-Gualtor, Joel and Lujan-Mora, Sergio},
doi = {10.1109/ACCESS.2019.2906343},
issn = {21693536},
journal = {IEEE Access},
keywords = {Big data,business intelligence,data warehouse,educational data mining,knowledge management},
language = {English},
pages = {38778--38788},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{A Hybrid Infrastructure of Enterprise Architecture and Business Intelligence Analytics for Knowledge Management in Education}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065168332&doi=10.1109%2FACCESS.2019.2906343&partnerID=40&md5=62a8081bcc0b7899e7c4e9aad42ba0f9},
volume = {7},
year = {2019}
}
@inproceedings{Torres2021,
abstract = {In the digital world, identity data and records are scattered across each digital service‚{\"{A}}{\^{o}}s database. Government entities, public and private companies hold their own instances of a person‚{\"{A}}{\^{o}}s set of credentials which are often outdated and seldom integrated. Such dissemination of data increases the attack surface for cyber-criminals and companies fail too frequently to protect the information, ...},
author = {{Alvarez Torres}, Daniel},
booktitle = {2021 Eighth International Conference on eDemocracy & eGovernment (ICEDEG)},
doi = {10.1109/ICEDEG52154.2021.9530967},
isbn = {978-1-6654-2512-4},
keywords = {Big Data,Blockchains,Business,Conferences,Financial services,Industries,Phishing},
month = {jul},
pages = {12--12},
publisher = {IEEE},
title = {{Tutorial: Decentralized Digital Identity with Blockchain}},
url = {https://ieeexplore.ieee.org/document/9530967/},
year = {2021}
}
@inproceedings{Herrera2020,
abstract = {Currently, IT solutions that detect situations of vehicle congestion use isolated technologies, which are not part of an ecosystem that manages them together, made it difficult to gear the tools used by affecting the operation of the solutions.This study aims to present a Big Data architecture proposal for the implementation of vehicle traffic detection software. The research is presented based on the base architecture established for Big Data systems, as well as established studies identifying the particular phases identified for the processing of vehicle traffic records collected in the city of Quito-Ecuador.},
author = {{Herrera Herrera}, Nelson Iv{\'{a}}n},
booktitle = {Proceedings - 2020 International Conference of Digital Transformation and Innovation Technology, INCODTRIN 2020},
doi = {10.1109/Incodtrin51881.2020.00034},
isbn = {9781665423199},
keywords = {Application,Architecture,Big Data,Twitter},
month = {oct},
pages = {118--122},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Big Data architecture proposal for vehicular traffic detection}},
year = {2020}
}
@incollection{Espinosa-Pinos2022,
abstract = {Several factors, directly and indirectly, influence students' performance in their various activities. Children and adolescents in the education process generate enormous data that could be analyzed to promote changes in current educational models. Therefore,...},
address = {Guayaquil},
author = {Espinosa-Pinos, Carlos Alberto and Ayala-Chauvin, Manuel and Buele, Jorge},
booktitle = {Communications in Computer and Information Science},
doi = {10.1007/978-3-031-19961-5_2},
keywords = {Academic performance,Machine learning,Random forest,Supervised learning},
mendeley-tags = {Academic performance,Machine learning,Random forest,Supervised learning},
pages = {15--29},
publisher = {Springer, Cham},
title = {{Predicting Academic Performance in Mathematics Using Machine Learning Algorithms}},
url = {https://link.springer.com/10.1007/978-3-031-19961-5_2},
volume = {1658},
year = {2022}
}
@conference{Montenegro20181,
abstract = {Using DSR approach, this research proposes the design and evaluation of a model type artifact for Software Development Governance in VSE Teams. Mainly, the model design is based on IT Governance best practices, COBIT 5, and SCRUM, with structural and dynamic components. The validation phase is done through the model application, in a case study, into an Ecuadorian Public Sector Organization. As a part of the research, the results of a survey show that, in a developing country, the IT and Software Development Governance practices are similar in public and private organizations, and in VSE and not-VSE teams. Besides, the model allowed to have the appropriate responses to the software requirements and facilitated the solution of the drawbacks presented in the project development. The work contributes providing a practical tool for the practitioners and academics and on the expansion of the existing body of knowledge in a topic where there is a research lack.},
annote = {cited By 2; Conference of 2018 International Conference on Software Engineering and Information Management, ICSIM 2018 and its Workshop 2018 International Conference on Big Data and Smart Computing, ICBDSC 2018 ; Conference Date: 4 January 2018 Through 6 January 2018; Conference Code:135377},
author = {Montenegro, Carlos and Ar{\'{e}}valo, Ren{\'{e}}},
booktitle = {ACM International Conference Proceeding Series},
doi = {10.1145/3178461.3178474},
isbn = {9781450354387},
keywords = {Agile process,COBIT,DSR,Software development governance,VSE},
pages = {1--5},
publisher = {Association for Computing Machinery},
title = {{Software Development Governance for VSE-SCRUM teams: Model and evaluation in a developing country}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045410774&doi=10.1145%2F3178461.3178474&partnerID=40&md5=425ff453f7c78894b2fbca5cad83346b},
year = {2018}
}
@inproceedings{Rodriguez-Echeverria2017,
abstract = {Nowadays, mobility campaigns use mobile phones as sensors for travel surveys aimed at gathering chronological information, patterns and modes used by citizens. Train trip travel identification is one of the issues present in this new schema. Differentiating train and car trips is challenging because in many cases railways and roads are side by side and their individual travels have similar speed. In this paper, we describe a methodology based on a speed-based filter and geospatial operation using the OSM network to determine possible train trip segments in data gathered in a mobility campaign. We evaluated our method using over 9,683 segments, which have been gathered by 239 devices. The results show that the proposed approach successfully detects 76.14 of the train trip segments labeled by users. This methodology can be used as a post-processing step to classify train segments in big data of smart cities.},
author = {Rodr{\'{i}}guez-Echeverr{\'{i}}a, Jorge and Gautama, Sidharta and Ochoa, Daniel},
booktitle = {2017 IEEE 1st Summer School on Smart Cities, S3C 2017 - Proceedings},
doi = {10.1109/S3C.2017.8501397},
isbn = {9781538610633},
keywords = {GIS,GPS,Mobility,transport mode classification},
pages = {141--144},
title = {{A methodology for train trip identification in mobility campaigns based on smart-phones}},
year = {2017}
}
@inproceedings{Tenesaca-Luna2017,
abstract = {The present work presents an analysis to terms related to Big Data, Hadoop and presents results by means of RHadoop the combination of two technologies as are R and Hadhoop, these technologies are complemented in an advantageous way, because it allows the analysis and visualization of large volumes Of data, in addition a case study of the tweet is generated that generates from a user account using Hadoop (Apache Hive) and the presentation of reports with RHadoop that support to the Managers of the organizations to a better decision-making. In order to do this, a detailed search has been made regarding Big Data, Hadoop Framework and the means of visualization and generation of a Data Volume with RHadoop, in which a synthesis of the different important terms was made, Arriving to determine different areas of application, in addition is presented a case study of a data volume with Hadoop applied to tweets generated from the social network Twitter. In this context it is concluded that with the help of the Hadoop Framework we can process a large volume of data, since its architecture has the Hadoop Distributed File System that provides a high performance of access to data of the application and Apache Hive that executes the processes In parallel with the integration of tools such as RHadoop allows the analysis of a large amount of information and submit reports that support the decision-making of organizations.},
author = {{Tenesaca Luna}, Gladys Alicia and Urena-Torres, Juan-Pablo and Arciniegas, Maria Belen Mora and Segarra-Faggioni, Ver{\'{o}}nica},
booktitle = {Iberian Conference on Information Systems and Technologies, CISTI},
doi = {10.23919/CISTI.2017.7975920},
isbn = {9789899843479},
issn = {21660735},
keywords = {Big Data,Decision making,RHadoop},
pages = {1--5},
title = {{Visualizaci{\'{o}}n de gr{\'{a}}ficos de an{\'{a}}lisis de datos con RHadoop}},
year = {2017}
}
@conference{Luna2017,
abstract = {Big Data covers a wide spectrum of technologies, which tends to support the processing of big amounts of heterogeneous data. The paper identifies the powerful benefits and the application areas of Big Data in the on-line education context. Considering the boom of academic services on-line, and the free access to the educative content, a great amount of data is being generated in the formal educational field as well as in less formal contexts. In this sense, Big Data can help stakeholders, involved in education decision making, to reach the objective of improving the quality of education and the learning outcomes. In this paper, a methodology is proposed to process big amounts of data coming from the educational field. The current study ends with a specific case study where the data of a well-known Ecuadorian institution that has more than 80 branches is analyzed.},
annote = {cited By 1; Conference of 35th International Conference of the Chilean Computer Science Society, SCCC 2016 ; Conference Date: 10 October 2016 Through 14 October 2016; Conference Code:126292},
author = {{Tenesaca Luna}, Gladys Alicia and Chicaiza, Janneth and {Mora Arciniegas}, Maria Belen and Urena-Torres, Juan-Pablo and Segarra-Faggioni, Ver{\'{o}}nica and Ludena, Marlon Santiago Vinan},
booktitle = {Proceedings - International Conference of the Chilean Computer Science Society, SCCC},
doi = {10.1109/SCCC.2016.7836014},
isbn = {9781509033393},
issn = {15224902},
keywords = {Big Data,Data Web,Dataset,Education,Hadoop,UTPL},
publisher = {IEEE Computer Society},
title = {{Contribution of big data in E-leaming. A methodology to process academic data from heterogeneous sources}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017615009&doi=10.1109%2FSCCC.2016.7836014&partnerID=40&md5=37cf842c6f7b6e95d8e63af4d1138dc4},
year = {2017}
}
@inproceedings{Lopez-Fierro2021a,
abstract = {Election times are commonly the scenes of massive political thoughts shared online. However, how reliable are all those opinions?. This work presents five traits of suspicious accounts that actively participated during the Ecuadorian presidential elections of 2021, and were exposed after analyzing the sentiment of 1,302,388 tweets.},
author = {L{\'{o}}pez-Fierro, Sariah and Chiriboga-Calderon, Carlos and Pacheco-Villamar, Rub{\'{e}}n},
booktitle = {Proceedings - 2021 IEEE International Conference on Big Data, Big Data 2021},
doi = {10.1109/BigData52589.2021.9671864},
file = {:C\:/Users/avile/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/L{\'{o}}pez-Fierro, Chiriboga-Calderon, Pacheco-Villamar - 2021 - If it looks, retweets and follows like a troll Is it a troll Targeting the 2.pdf:pdf;:C\:/Users/avile/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/L{\'{o}}pez-Fierro, Chiriboga-Calderon, Pacheco-Villamar - 2021 - If it looks, retweets and follows like a troll Is it a troll Targeting th(2).pdf:pdf},
isbn = {9781665439022},
keywords = {Data Analysis,Presidential Elections,Sentiment Analysis,Trolls,Twitter},
month = {dec},
pages = {2503--2509},
publisher = {IEEE},
title = {{If it looks, retweets and follows like a troll; Is it a troll?: Targeting the 2021 Ecuadorian Presidential Elections Trolls}},
url = {https://ieeexplore.ieee.org/document/9671864/},
year = {2021}
}
@incollection{Lopez-Fierro2021,
abstract = {This document contains an approach for the implementation of a sentiment analysis alternative after using Google Sheets for the rating of tweets retrieved with respect to the Ecuadorian Presidential 2021 Campaign.},
author = {L{\'{o}}pez-Fierro, Sariah and Chiriboga-Calderon, Carlos and Pacheco-Villamar, Rub{\'{e}}n},
booktitle = {IX Jornadas de Cloud Computing, Big Data & Emerging Topics},
file = {:C\:/Users/avile/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/L{\'{o}}pez-Fierro, Chiriboga, Pacheco - 2021 - Designing a Sentiments Analysis Alternative for rating tweets regarding the Ecuadorian 2021 Pr.pdf:pdf;:C\:/Users/avile/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/L{\'{o}}pez-Fierro, Chiriboga, Pacheco - 2021 - Designing a Sentiments Analysis Alternative for rating tweets regarding the Ecuadorian 2021(2).pdf:pdf},
isbn = {978-950-34-2016-4},
keywords = {Ciencias Inform{\'{a}}ticas,Data Analysis,Google Clouds,Google Sheets,Google clouds,Querying,Semantic Web,Sentiment Analysis,Sheets {\textperiodcentered}},
mendeley-tags = {Data Analysis,Google Sheets,Google clouds,Querying,Sentiment Analysis},
title = {{Designing a Sentiments Analysis Alternative for rating tweets regarding the Ecuadorian 2021 Presidential Campaigns}},
url = {http://sedici.unlp.edu.ar/handle/10915/125146},
year = {2021}
}
@article{Estupinan2021,
abstract = {The occurrence of earthquakes may have catastrophic and devastating consequences for the inhabitants of the place where they occur. Some regions are characterized by the high frequency of this type of natural phenomenon. Such is the case of Ecuador, a country with a high seismic index due to its location in a subduction zone between the Pacific Plate and the South American Plate. Predictions in the behavior of earthquakes are a way of prevention that allows taking measures according to vulnerability. Although it is difficult to accurately predict the occurrence of an earthquake, there are dissimilar types of analysis to observe its behavior and patterns of occurrence. The nature of earthquakes and their monitoring variables usually make up large databases. For its processing and subsequent analysis of the results, it is convenient to use statistical techniques of Data Mining such as K-Means. In this work, the classic K-Means method is combined with Neutrosophy to improve the results obtained by taking into account the indeterminacy of such complex data sets and including the diversity of the data and its fluctuation, due to the proximity among the boundaries and their membership clusters.},
author = {Estupi{\~{n}}{\'{a}}n, Jes{\'{u}}s Ricardo and {Dom{\'{i}}nguez Men{\'{e}}ndez}, Jorge and {Barcos Arias}, Ignacio and {Mac{\'{i}}as Berm{\'{u}}dez}, Jorge and {Moreno Lemus}, Noel},
file = {:C\:/Users/avile/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Estupi{\~{n}}{\'{a}}n et al. - 2021 - Neutrosophic K-means for the analysis of earthquake data in Ecuador.pdf:pdf},
issn = {2331-608X},
journal = {Neutrosophic Sets and Systems},
keywords = {K-means clustering,Neutrosophy,earthquakes,neutrosophy,prediction,vulnerability},
mendeley-tags = {K-means clustering,earthquakes,neutrosophy,prediction,vulnerability},
month = {aug},
number = {1},
title = {{Neutrosophic K-means for the analysis of earthquake data in Ecuador}},
url = {https://digitalrepository.unm.edu/nss_journal/vol44/iss1/29},
volume = {44},
year = {2021}
}
